{"cells":[{"cell_type":"markdown","id":"25533d3b","metadata":{"id":"25533d3b"},"source":["# 실습 3: 자동미분(AutoDiff) 라이브러리"]},{"cell_type":"markdown","id":"f60968f6","metadata":{"id":"f60968f6"},"source":["앞서 우리는 그래디언트 기반 학습에 대해 살펴보았다. $\\mathscr{L}$이 간단한 함수일 때는 편미분하는 것이 간단한 일이었지만, 앞으로는 손으로 편미분을 계산하기는 어려운 다양한 함수들을 $\\mathscr{L}$ 로 만나게 될 것이다. 이럴 때 필요한 것이 바로 컴퓨터의 계산 능력이다. 그래디언트 기반 학습에 대한 관심이 크게 증가하면서, 미분을 자동으로 계산해주는 자동미분 라이브러리가 여럿 개발되었다. 널리 쓰이는 라이브러리로는 [PyTorch](https://pytorch.org/), [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax), [Zygote](https://github.com/FluxML/Zygote.jl) 등이 있다.\n","\n","이 책에서는 위의 라이브러리 중에서 쉽게 이해하고 사용할 수 있는 PyTorch 라이브러리를 사용할 것이다. 이 라이브러리는 NumPy 라이브러리와 매우 유사하게 동작하기 때문에, NumPy만 잘 알아도 쉽게 사용할 수 있다. NumPy에서 ndarray(배열)가 기본이 되는 핵심 객체인 것과 같이, PyTorch의 핵심 객체는 Tensor(텐서)라고 부른다. 이 Tensor는 ndarray와 매우 유사하게 동작이 가능하다.\n","\n","이 실습에서 PyTorch를 통한 자동미분에 익숙해지고 나면, 이 책 전반에 걸쳐 PyTorch를 자유자재로 사용하며 딥러닝을 배우게 될 것이다."]},{"cell_type":"code","execution_count":3,"id":"e93acc4d","metadata":{"id":"e93acc4d","executionInfo":{"status":"ok","timestamp":1720162216442,"user_tz":-540,"elapsed":3726,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["import torch\n","import torch as tc\n","import numpy as np"]},{"cell_type":"markdown","id":"03d35d08","metadata":{"id":"03d35d08"},"source":["구글 코랩(Google Colab)에서는 PyTorch가 기본적으로 설치되어 있다. 따라서 별도로 설치할 필요 없이 바로 사용 가능하다. PyTorch가 제대로 설치되어 있는지 확인하려면 아래와 같은 코드를 실행해볼 수 있다.\n","torch.cuda.is_available() 코드가 False의 결과가 나오면 메뉴에서\n","\n","런타임 > 런타임 유형 변경 > 하드웨어 가속기\n","\n","에서 보면 CPU가 선택되어 있을 것인데 이를 GPU로 바꿔줘야 한다."]},{"cell_type":"code","execution_count":2,"id":"kPxSBddWT2OT","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kPxSBddWT2OT","outputId":"1b43695e-721e-41a4-b1e4-30b63183f7c0","executionInfo":{"status":"ok","timestamp":1720146892055,"user_tz":-540,"elapsed":531,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["2.3.0+cu121\n","True\n"]}],"source":["print(torch.__version__)\n","print(torch.cuda.is_available())"]},{"cell_type":"markdown","id":"a73926ed","metadata":{"id":"a73926ed"},"source":["### Step 1. PyTorch의 여러가지 함수"]},{"cell_type":"markdown","id":"335815d5","metadata":{"id":"335815d5"},"source":["라이브러리를 사용할 때, 유명한 라이브러리의 경우에는 구글링을 통해 쉽게 설명된 블로그 등을 참고할 수도 있다. 하지만 정석은 라이브러리 개발자가 작성한 도큐먼트(document)를 읽는 것이다. 이 실습에서는 PyTorch를 사용한 자동미분을 배우는 것을 가장 중요한 목적으로 다루고 있으므로, 더 다양한 함수와 기능이 궁금하다면 직접 [도큐먼트](https://mygrad.readthedocs.io/en/latest/)를 읽어보길 바란다. 또한, NumPy의 기본 함수들과 일치하는 함수를 많이 가지고 있으므로, NumPy의 함수들을 찾아 PyTorch에 적용해보아도 좋다."]},{"cell_type":"markdown","id":"d06b0a0d","metadata":{"id":"d06b0a0d"},"source":["#### Tensor 생성\n","Tensor는 Pytorch 라이브러리에서 사용하는 데이터를 배열 형식으로 저장하도록 한다. 다양한 방식으로 Tensor를 생성할 수 있다. 다음은 Tensor를 생성하는 여러 가지 예이다. tc.tensor 외에도 Tensor를 생성하는 다양한 함수들이 있다. 직접 코드를 실행하여 output을 확인해보자."]},{"cell_type":"code","execution_count":3,"id":"42d2424d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"42d2424d","outputId":"d36eb387-684f-4206-ad4e-eee746a97289","executionInfo":{"status":"ok","timestamp":1720146898117,"user_tz":-540,"elapsed":541,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.3000)"]},"metadata":{},"execution_count":3}],"source":["# 단일 숫자로 생성한 Tensor\n","tc.tensor(2.3)"]},{"cell_type":"code","execution_count":4,"id":"4b71a705","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4b71a705","outputId":"aab55cd3-4945-4050-80fb-53526ccdd43c","executionInfo":{"status":"ok","timestamp":1720146909352,"user_tz":-540,"elapsed":499,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1., 2., 3.])"]},"metadata":{},"execution_count":4}],"source":["# 시퀀스(리스트, 튜플 등) 자료형으로 생성한 Tensor.\n","# dtype을 지정할 수 있는 모든 함수에서\n","# 32-bit floats를 저장하는 텐서를 반환하도록 지정 가능.\n","tc.tensor([1.0, 2.0, 3.0], dtype=tc.float32)"]},{"cell_type":"code","execution_count":5,"id":"737f62f3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"737f62f3","outputId":"a666642c-bec1-46e9-8b2a-2b74b19166e2","executionInfo":{"status":"ok","timestamp":1720146914626,"user_tz":-540,"elapsed":603,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]], dtype=torch.float64)"]},"metadata":{},"execution_count":5}],"source":["# numpy.ndarray로부터 생성한 Tensor\n","arr = np.ones((3,3))\n","tc.tensor(arr)"]},{"cell_type":"code","execution_count":6,"id":"970b3585","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"970b3585","outputId":"a3088497-5bb0-4c36-ddb7-5a19c09530c5","executionInfo":{"status":"ok","timestamp":1720147544515,"user_tz":-540,"elapsed":509,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]],\n","\n","        [[0., 0., 0., 0.],\n","         [0., 0., 0., 0.],\n","         [0., 0., 0., 0.]]])"]},"metadata":{},"execution_count":6}],"source":["# Tensor 생성 함수 (ones, zeros; 각각 1, 0으로 채움)\n","tc.zeros((2,3,4))"]},{"cell_type":"code","execution_count":7,"id":"dbe81f6c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dbe81f6c","outputId":"2b5f5cc2-01bc-4224-a634-db4075ef02d7","executionInfo":{"status":"ok","timestamp":1720147621717,"user_tz":-540,"elapsed":538,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-5, -3, -1,  1,  3,  5,  7,  9, 11, 13])"]},"metadata":{},"execution_count":7}],"source":["# Tensor 생성 함수 (start 부터 stop 까지 step 만큼 띄워가며 채움)\n","tc.arange(-5, 15, 2)"]},{"cell_type":"code","execution_count":8,"id":"ae113b63","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ae113b63","outputId":"79f49259-5156-4c74-9396-b3e36ce53832","executionInfo":{"status":"ok","timestamp":1720147710577,"user_tz":-540,"elapsed":541,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])"]},"metadata":{},"execution_count":8}],"source":["# start = 0, step = 1이 default 값\n","tc.arange(9.)"]},{"cell_type":"code","execution_count":9,"id":"fbdb971e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbdb971e","outputId":"ff7d063e-5b96-4277-99a9-0c6aa5201fe0","executionInfo":{"status":"ok","timestamp":1720147769662,"user_tz":-540,"elapsed":513,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.3910, 0.0652, 0.9978, 0.1433],\n","        [0.4048, 0.5888, 0.1284, 0.0027],\n","        [0.2560, 0.5306, 0.4709, 0.7783]])"]},"metadata":{},"execution_count":9}],"source":["# 0~1 사이의 값 무작위로 리턴 (확률분포는 균등분포(uniform))\n","tc.rand(3,4)"]},{"cell_type":"markdown","id":"9373be2a","metadata":{"id":"9373be2a"},"source":["<문제: 주어진 조건을 만족하는 Tensor 생성하기>\n","\n","구간 $[0, \\pi]$에 등간격으로 분포한 15개의 구성요소로 이루어진 shape-(15,)인 tensor를 만들어보자. (Hint: tc.linspace(), tc.pi)"]},{"cell_type":"code","execution_count":10,"id":"82ebd43d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"82ebd43d","outputId":"faccdd06-c911-4128-9fcf-9a31a5be6d71","scrolled":false,"executionInfo":{"status":"ok","timestamp":1720147842980,"user_tz":-540,"elapsed":510,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0000, 0.2244, 0.4488, 0.6732, 0.8976, 1.1220, 1.3464, 1.5708, 1.7952,\n","        2.0196, 2.2440, 2.4684, 2.6928, 2.9172, 3.1416])"]},"metadata":{},"execution_count":10}],"source":["# 여기에 코드 작성\n","tc.linspace(0, tc.pi, 15)"]},{"cell_type":"markdown","id":"71697cae","metadata":{"id":"71697cae"},"source":["#### Tensor 변형\n","Tensor의 모양을 변형하는 함수들도 있다. 직접 코드를 실행하여 output을 확인해보자."]},{"cell_type":"code","execution_count":11,"id":"38946f50","metadata":{"id":"38946f50","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720147946102,"user_tz":-540,"elapsed":617,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"3a9c8fbd-4295-4f2d-95fa-adce5e14f133"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0., 1., 2.],\n","        [3., 4., 5.],\n","        [6., 7., 8.]])"]},"metadata":{},"execution_count":11}],"source":["# Tensor의 행과 열을 바꾸어주는 함수\n","x = tc.arange(9.) #Tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.])\n","x.reshape(3,3)"]},{"cell_type":"code","execution_count":13,"id":"3a22b453","metadata":{"id":"3a22b453","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720147983531,"user_tz":-540,"elapsed":537,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"5164784a-3eed-4ed1-d4b7-57e21f82fd8b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0,  3,  6,  9],\n","        [ 1,  4,  7, 10],\n","        [ 2,  5,  8, 11]])"]},"metadata":{},"execution_count":13}],"source":["# Tensor의 전치 행렬을 구하는 함수\n","x = tc.tensor([[0,1,2],[3,4,5],[6,7,8],[9,10,11]])\n","x.t()"]},{"cell_type":"code","execution_count":14,"id":"a38b3441","metadata":{"id":"a38b3441","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148050755,"user_tz":-540,"elapsed":512,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"e9200e7f-241d-4d6b-bd9c-19302b2361ff"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3, 4, 5])"]},"metadata":{},"execution_count":14}],"source":["# 슬라이싱 (자유자재로 쓸 수 있으면 좋다)\n","x = tc.tensor(([1,2,3,4,5],[6,7,8,9,10]))\n","x[0, 2:]"]},{"cell_type":"code","execution_count":15,"id":"6320c0ee","metadata":{"id":"6320c0ee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148109846,"user_tz":-540,"elapsed":518,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"d66d7f3b-5b90-445f-dfe5-af966f864e17"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([3, 4, 5])"]},"metadata":{},"execution_count":15}],"source":["x = tc.tensor([[1,2,3,4,5],[6,7,8,9,10]])\n","x[0, -3:]"]},{"cell_type":"markdown","id":"6232d6c1","metadata":{"id":"6232d6c1"},"source":["#### Tensor 표준 수학 연산\n","\n","먼저, PyTorch에서 제공하는 표준적인 수학 함수들을 알아보자. 기본적인 산술 연산을 하는 함수를 비롯하여, (sum, mean, var, std, max, min) 등의 통계량을 구하는 함수 등이 제공된다. 또한, 삼각함수, 쌍곡함수, 지수함수, 로그함수 등의 초월함수도 제공된다. NumPy의 함수들과 동일하게, 벡터화된 함수들이다.\n","\n","단항 함수는 텐서에 대해 요소별로 각각 작동한다. 이항 함수는 두 텐서에 대해 대응되는 위치의 요소 간에 자연스럽게 작동한다. 두 텐서가 동일한 모양이 아니더라도 Numpy와 같은 [브로드캐스팅(Broadcasting)](https://numpy.org/doc/stable/user/basics.broadcasting.html) 규칙을 따르기 때문에, 이항 함수가 작동할 수 있는 경우가 있다.\n","\n","직접 코드를 실행하여 output을 확인해보자. 이를 통해 단항 연산과 이항 연산을 다루는 여러 함수에 대해 이해해보자."]},{"cell_type":"code","execution_count":16,"id":"b4d930c8","metadata":{"id":"b4d930c8","executionInfo":{"status":"ok","timestamp":1720148119569,"user_tz":-540,"elapsed":513,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["x = tc.tensor([0.0, 0.25, 0.5, 0.75, 1.0])\n","y = tc.tensor([[0.],[1.],[2.]])\n","z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])"]},{"cell_type":"code","execution_count":17,"id":"aa53ba6b","metadata":{"id":"aa53ba6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148168553,"user_tz":-540,"elapsed":506,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"3c13912d-4e16-44c8-c52d-12de86aca27a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0.0000, 0.2474, 0.4794, 0.6816, 0.8415])"]},"metadata":{},"execution_count":17}],"source":["# 단항 함수 중 하나인 삼각함수 sin()\n","# 텐서의 모든 요소의 sin 값으로 채워진 같은 크기의 텐서\n","tc.sin(x)"]},{"cell_type":"code","execution_count":18,"id":"27891022","metadata":{"id":"27891022","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148187978,"user_tz":-540,"elapsed":4,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"25e85674-dab9-4597-a880-8dffdb686bed"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(66)"]},"metadata":{},"execution_count":18}],"source":["# 단항 함수 중 통계량을 구하는 함수들은 axis 인자를 가짐\n","# axis가 0이면 행에 대해서만 함수를 적용하고,\n","# axis가 1이면 열에 대해서만 함수를 적용\n","tc.sum(z)"]},{"cell_type":"code","execution_count":19,"id":"99ed2ce2","metadata":{"id":"99ed2ce2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148215676,"user_tz":-540,"elapsed":3,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"962f5431-1595-4b52-b498-aada8514fbc0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([12, 15, 18, 21])"]},"metadata":{},"execution_count":19}],"source":["tc.sum(z, axis=0)"]},{"cell_type":"markdown","id":"628e8b1b","metadata":{"id":"628e8b1b"},"source":["z = tc.tensor([[0,1,2,3],[4,5,6,7],[8,9,10,11]])\n","\n","=>\n","\n","$[[0,1,2,3], \\\\\n","    [4,5,6,7], \\\\\n","    [8,9,10,11]]$"]},{"cell_type":"code","execution_count":20,"id":"9fe0294b","metadata":{"id":"9fe0294b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148279552,"user_tz":-540,"elapsed":519,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"42ad411e-4ca3-45fa-eb06-86edfcf64c71"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 6, 22, 38])"]},"metadata":{},"execution_count":20}],"source":["tc.sum(z, axis=1)"]},{"cell_type":"code","execution_count":21,"id":"b9686434","metadata":{"id":"b9686434","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148333794,"user_tz":-540,"elapsed":614,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"23a17590-46bb-4a3f-eddc-16dd7971d25a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n","        [1.0000, 1.2500, 1.5000, 1.7500, 2.0000],\n","        [2.0000, 2.2500, 2.5000, 2.7500, 3.0000]])"]},"metadata":{},"execution_count":21}],"source":["# 브로드캐스팅 예(1)\n","# x+y, y+z는 브로드캐스팅이 가능, x+z는 불가능\n","x+y"]},{"cell_type":"code","execution_count":22,"id":"6c0e5310","metadata":{"id":"6c0e5310","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148358194,"user_tz":-540,"elapsed":602,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"ee9c39cb-71db-4a4d-9e04-825c807778b7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  1.,  2.,  3.],\n","        [ 5.,  6.,  7.,  8.],\n","        [10., 11., 12., 13.]])"]},"metadata":{},"execution_count":22}],"source":["y+z"]},{"cell_type":"code","execution_count":23,"id":"ef7e7090","metadata":{"id":"ef7e7090","colab":{"base_uri":"https://localhost:8080/","height":144},"executionInfo":{"status":"error","timestamp":1720148395922,"user_tz":-540,"elapsed":591,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"180312a5-4d85-4813-db43-5209a8e6f623"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-0e52b3dd32a7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz\u001b[0m \u001b[0;31m# Error 발생\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (5) must match the size of tensor b (4) at non-singleton dimension 1"]}],"source":["x+z # Error 발생"]},{"cell_type":"code","execution_count":24,"id":"942ebf93","metadata":{"id":"942ebf93","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148458713,"user_tz":-540,"elapsed":4,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"ca00419c-d817-429e-ffcf-ba7c43638de3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n","        [0.0000, 0.2500, 0.5000, 0.7500, 1.0000],\n","        [0.0000, 0.5000, 1.0000, 1.5000, 2.0000]])"]},"metadata":{},"execution_count":24}],"source":["# 브로드캐스팅 예(2)\n","# x*y, y*z는 브로드캐스팅이 가능, x*z는 불가능\n","x*y"]},{"cell_type":"code","execution_count":25,"id":"45b61b7f","metadata":{"id":"45b61b7f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148463050,"user_tz":-540,"elapsed":2,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"3686b945-6931-4ebb-949a-0494aa35cdf8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0.,  0.,  0.,  0.],\n","        [ 4.,  5.,  6.,  7.],\n","        [16., 18., 20., 22.]])"]},"metadata":{},"execution_count":25}],"source":["y*z"]},{"cell_type":"code","execution_count":null,"id":"6b613e37","metadata":{"id":"6b613e37"},"outputs":[],"source":["x*z # Error 발생"]},{"cell_type":"markdown","id":"ad45aec1","metadata":{"id":"ad45aec1"},"source":["<문제: Pytorch의 기본 수학 연산>\n","\n","아래와 같이 정의된 텐서 x에 대해 여러 가지 수학 연산을 적용하여 여러 가지 텐서를 구해보자."]},{"cell_type":"code","execution_count":5,"id":"a98929d0","metadata":{"id":"a98929d0","executionInfo":{"status":"ok","timestamp":1720162228739,"user_tz":-540,"elapsed":394,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["x = tc.Tensor([[ 0.,  1.,  2.,  3.],\n","...                [ 4.,  5.,  6.,  7.],\n","...                [ 8.,  9., 10., 11.],\n","...                [12., 13., 14., 15.]])"]},{"cell_type":"markdown","source":["## 1번 문제"],"metadata":{"id":"prqrJypdiwJ2"},"id":"prqrJypdiwJ2"},{"cell_type":"markdown","id":"6e03887e","metadata":{"id":"6e03887e"},"source":["1. x의 3행의 첫번째, 세번째 원소에 대한 자연로그 값으로 채워진 shape-(2,)인 Tensor를 구해보자."]},{"cell_type":"code","execution_count":28,"id":"7b89e057","metadata":{"id":"7b89e057","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720148626217,"user_tz":-540,"elapsed":697,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"2108030c-11c5-4154-b94e-8c82d9a90096"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([2.0794, 2.3026])"]},"metadata":{},"execution_count":28}],"source":["# 여기에 코드 작성\n","tc.log(x[2,0::2])"]},{"cell_type":"markdown","id":"3d1e928f","metadata":{"id":"3d1e928f"},"source":["## 1번 문제 정답"]},{"cell_type":"code","source":["tc.log(x[2,0::2])"],"metadata":{"id":"2wSGga_FiWIq"},"id":"2wSGga_FiWIq","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1번 문제 출력 결과 : tensor([2.0794, 2.3026])"],"metadata":{"id":"F7fzgO9kikUX"},"id":"F7fzgO9kikUX"},{"cell_type":"markdown","source":["# 2번 문제"],"metadata":{"id":"6M3xaJomisFT"},"id":"6M3xaJomisFT"},{"cell_type":"markdown","id":"65c19bdd","metadata":{"id":"65c19bdd"},"source":["2. x를 가로, 세로로 4등분한 각 귀퉁이(왼쪽 위, 오른쪽 위, 왼쪽 아래, 오른쪽 아래)의 4개 원소를 더하여 shape-(2,2)인 Tensor를 구해보자."]},{"cell_type":"code","execution_count":6,"id":"b0076def","metadata":{"id":"b0076def","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720162233202,"user_tz":-540,"elapsed":375,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"30d2eec8-4ea5-4671-fd16-38467463fd21"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[20., 24.],\n","        [36., 40.]])"]},"metadata":{},"execution_count":6}],"source":["# 여기에 코드 작성\n","x[:2, :2] + x[:2, 2:] + x[2:, :2] + x[2:, 2:]"]},{"cell_type":"markdown","source":["## 2번 문제 정답"],"metadata":{"id":"AyY6znLKidQj"},"id":"AyY6znLKidQj"},{"cell_type":"code","source":["x[:2,:2] + x[:2,2:] + x[2:,:2] + x[2:,2:]"],"metadata":{"id":"a3JavlrAi3Nn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720162237611,"user_tz":-540,"elapsed":381,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"9a24ba9d-1352-47f2-bfb7-3aaf9ff35dee"},"id":"a3JavlrAi3Nn","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[20., 24.],\n","        [36., 40.]])"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["2번 문제 출력 결과 :\n","\n","tensor([[20., 24.],\\\n","        [36., 40.]])"],"metadata":{"id":"2ZYKqDfmjKFu"},"id":"2ZYKqDfmjKFu"},{"cell_type":"markdown","source":["## 3번 문제"],"metadata":{"id":"t8AcEm9Ni-9i"},"id":"t8AcEm9Ni-9i"},{"cell_type":"markdown","id":"d18ec6e0","metadata":{"id":"d18ec6e0"},"source":["  3. x의 각 열의 평균을 구하여 shape-(4,)인 Tensor를 구해보자."]},{"cell_type":"code","execution_count":8,"id":"5ff6a6bc","metadata":{"id":"5ff6a6bc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720162311445,"user_tz":-540,"elapsed":385,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"8a603ee3-fc25-4b49-fb58-ec26e0ce66d7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([6., 7., 8., 9.])"]},"metadata":{},"execution_count":8}],"source":["# 여기에 코드 작성\n","x.mean(axis=0)"]},{"cell_type":"markdown","source":["## 3번 문제 정답"],"metadata":{"id":"Mf_Q1BkEjoCf"},"id":"Mf_Q1BkEjoCf"},{"cell_type":"code","source":["x.mean(axis=0)"],"metadata":{"id":"-pmoGU-0jnk5"},"id":"-pmoGU-0jnk5","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3번 문제 출력 결과 : tensor([6., 7., 8., 9.])"],"metadata":{"id":"Pn-E0xyKjobv"},"id":"Pn-E0xyKjobv"},{"cell_type":"markdown","source":["# 4번 문제"],"metadata":{"id":"W7y-HGgwjzr7"},"id":"W7y-HGgwjzr7"},{"cell_type":"markdown","id":"d29b6965","metadata":{"id":"d29b6965"},"source":["4. x의 각 행을 벡터로보고, 각 벡터가 크기가 1이 되도록 정규화하여 shape-(4,4)인 Tensor로 업데이트해보자."]},{"cell_type":"code","execution_count":9,"id":"57234e34","metadata":{"id":"57234e34","executionInfo":{"status":"ok","timestamp":1720162365422,"user_tz":-540,"elapsed":383,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["# 여기에 코드 작성\n","x /= tc.sqrt(tc.sum(x**2, axis=1, keepdims = True))"]},{"cell_type":"code","execution_count":10,"id":"d038eb54","metadata":{"id":"d038eb54","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720162386831,"user_tz":-540,"elapsed":356,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"c963986f-a09f-4c2b-efb6-ee51460d4321"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([1.0000, 1.0000, 1.0000, 1.0000])"]},"metadata":{},"execution_count":10}],"source":["# 정규화가 잘 되었는지 확인하기\n","(x**2).sum(axis=1)"]},{"cell_type":"markdown","source":["## 4번 문제 정답"],"metadata":{"id":"-zPuP1PPj_yj"},"id":"-zPuP1PPj_yj"},{"cell_type":"code","source":["x /= tc.sqrt(tc.sum(x**2,axis=1,keepdims = True))\n","x"],"metadata":{"id":"hZ_679jyj3rQ"},"id":"hZ_679jyj3rQ","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4번 문제 출력 결과 : \\\\\n","\n","tensor([[0.0000, 0.2673, 0.5345, 0.8018], \\\n","        [0.3563, 0.4454, 0.5345, 0.6236], \\\n","        [0.4182, 0.4704, 0.5227, 0.5750], \\\n","        [0.4429, 0.4798, 0.5167, 0.5537]])"],"metadata":{"id":"dVP8WS0PkDKT"},"id":"dVP8WS0PkDKT"},{"cell_type":"code","source":["# 정규화가 잘 되었는지 확인하기 정답\n","(x**2).sum(axis=1)"],"metadata":{"id":"J9xPBjRsj3ff"},"id":"J9xPBjRsj3ff","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#   "],"metadata":{"id":"n8GyohNmkccZ"},"id":"n8GyohNmkccZ"},{"cell_type":"markdown","id":"ca7b8e69","metadata":{"id":"ca7b8e69"},"source":["#### 선형대수 연산 함수"]},{"cell_type":"markdown","id":"47ce788e","metadata":{"id":"47ce788e"},"source":["PyTorch에는 선형대수 연산을 쉽게 계산하도록 도와주는 함수들도 있다. matmul()은 행렬곱을 계산해주는 함수이다. 이를 이용하여 벡터의 점곱(스칼라곱)을 계산할 수도 있다. einsum()은 아인슈타인 표기법(Einstein notation 또는 Einstein summation convention)을 계산하는 함수이다. 이는 다소 복잡한 함수이지만, 다양한 사용자 지정 가능한 선형 대수 연산을 수행할 수 있다. PyTorch가 자동미분을 수행할 때 이 연산들을 통해 수행한다."]},{"cell_type":"markdown","id":"171b9c09","metadata":{"id":"171b9c09"},"source":["먼저 이항 연산 함수인 matmul()연산은 행렬곱을 기본으로 하는 함수이므로 2차원 텐서 간의 연산이 가장 자연스럽게 정의된다. 1차원 텐서 간의 matmul()을 명령하면 1차원 텐서를 1xn 크기의 2차원 텐서로 생각하여 연산을 진행한다. 그리고 n차원(3차원 이상)의 텐서 간의 matmul()은 n-2차원의 텐서의 구성요소가 2차원 텐서(행렬)인 것으로 생각하여 연산을 진행한다. 즉, 행렬이 여러개 모여있는 것으로 생각하고 행렬곱을 진행하는 것이다. matmul()연산 또한 NumPy의 브로드캐스팅 규칙을 따르는 함수이기 때문에 3차원 이상의 텐서에 대해서는 브로드캐스팅에도 유의해야 한다.\n","\n","matmul()을 사용할 때는 tc.matmul(x,y)로 사용할 수 있지만, x @ y 와 같이 연산자 @를 이용하여도 같은 연산을 할 수 있도록 정의되어 있다. 아래의 사용 예시를 따라가면 matmul() 함수의 사용법을 이해할 수 있을 것이다. 직접 코드를 실행하여 output을 확인해보자."]},{"cell_type":"code","execution_count":15,"id":"c0d89dcb","metadata":{"id":"c0d89dcb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720162446492,"user_tz":-540,"elapsed":3,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"e8ba944e-520e-4b3d-c568-0fb35e5f011f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-11.)"]},"metadata":{},"execution_count":15}],"source":["# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n","x = tc.tensor([1.0, 2.0])\n","y = tc.tensor([-3.0, -4.0])\n","tc.matmul(x,y)"]},{"cell_type":"code","source":["# 1차원 텐서의 matmul 연산은 점곱(스칼라곱)을 구하는 것과 같음\n","x = tc.tensor([1.0, 2.0])\n","y = tc.tensor([-3.0, -4.0])\n","x@y"],"metadata":{"id":"oKmJhLeklBTI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720162462261,"user_tz":-540,"elapsed":2,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"2c98fb0d-5182-49ce-b36a-7c536da2ccf7"},"id":"oKmJhLeklBTI","execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-11.)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","execution_count":17,"id":"594d0ad6","metadata":{"id":"594d0ad6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720162473023,"user_tz":-540,"elapsed":3,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"b3768bb3-3990-4397-e176-5d44b4c563bf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 4,  1,  5],\n","        [ 2,  2,  6],\n","        [10,  4, 16],\n","        [20, 11, 39]])"]},"metadata":{},"execution_count":17}],"source":["# 2차원 텐서의 matmul 연산은 그냥 행렬곱과 같음\n","a = tc.tensor([[1, 0], [0, 1], [2, 1], [3, 4]])\n","b = tc.tensor([[4, 1, 5], [2, 2, 6]])\n","tc.matmul(a,b) # a @ b"]},{"cell_type":"code","execution_count":18,"id":"375463a3","metadata":{"id":"375463a3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163247349,"user_tz":-540,"elapsed":460,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"779dced5-95a8-43ac-949b-ac33edb8db93"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0,  1,  2],\n","         [ 3,  4,  5]],\n","\n","        [[ 2,  3,  4],\n","         [ 5,  6,  7]],\n","\n","        [[ 4,  5,  6],\n","         [ 7,  8,  9]],\n","\n","        [[ 6,  7,  8],\n","         [ 9, 10, 11]]])\n","tensor([[[ 0,  1,  2],\n","         [ 3,  4,  5],\n","         [ 6,  7,  8]],\n","\n","        [[ 2,  3,  4],\n","         [ 5,  6,  7],\n","         [ 8,  9, 10]],\n","\n","        [[ 4,  5,  6],\n","         [ 7,  8,  9],\n","         [10, 11, 12]],\n","\n","        [[ 6,  7,  8],\n","         [ 9, 10, 11],\n","         [12, 13, 14]]])\n","tensor([[[ 15,  18,  21],\n","         [ 42,  54,  66]],\n","\n","        [[ 51,  60,  69],\n","         [ 96, 114, 132]],\n","\n","        [[111, 126, 141],\n","         [174, 198, 222]],\n","\n","        [[195, 216, 237],\n","         [276, 306, 336]]])\n"]}],"source":["# A는 크기가 (4, 2, 3)인 3차원 텐서\n","A1 = tc.arange(2*3).reshape((2,3))\n","A = tc.stack([A1, A1+2, A1+4, A1+6])\n","\n","# B는 크기가 (4, 3, 3)인 3차원 텐서\n","B1 = tc.arange(3*3).reshape((3,3))\n","B = tc.stack([B1, B1+2, B1+4, B1+6])\n","\n","# matmul 연산을 제대로 이해했는지 확인하기 위해\n","# 손으로도 직접 계산해보고, 결과가 동일한지 확인해보기\n","print(A)\n","print(B)\n","print(tc.matmul(A, B))"]},{"cell_type":"code","execution_count":19,"id":"6479f8f0","metadata":{"id":"6479f8f0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163395691,"user_tz":-540,"elapsed":385,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"c619262f-9109-4a9a-9814-f5a9828fef00"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4, 2, 3])\n","tensor([[[ 15,  18,  21],\n","         [ 42,  54,  66]],\n","\n","        [[ 51,  60,  69],\n","         [ 96, 114, 132]],\n","\n","        [[111, 126, 141],\n","         [174, 198, 222]],\n","\n","        [[195, 216, 237],\n","         [276, 306, 336]]])\n"]}],"source":["C = tc.matmul(A,B)\n","print(C.shape)\n","print(C)"]},{"cell_type":"code","execution_count":20,"id":"e4b01755","metadata":{"id":"e4b01755","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163427021,"user_tz":-540,"elapsed":402,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"91b18d57-4616-465a-916c-80d951c610c5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[1.3646, 0.8793],\n","         [1.1331, 0.6446],\n","         [1.3926, 0.7634]],\n","\n","        [[0.1998, 0.1714],\n","         [1.0673, 0.7441],\n","         [0.6147, 0.4180]],\n","\n","        [[0.6856, 0.4307],\n","         [0.5345, 0.3864],\n","         [0.7993, 0.4736]],\n","\n","        [[0.7441, 0.3859],\n","         [0.2057, 0.1929],\n","         [1.2180, 0.8129]],\n","\n","        [[1.0916, 0.6135],\n","         [1.1342, 0.7460],\n","         [0.3639, 0.3298]]])"]},"metadata":{},"execution_count":20}],"source":["# 브로드캐스팅 예 (y를 5개로 브로드캐스팅하여 x와 연산)\n","x = tc.rand(5,3,4)\n","y = tc.rand(4,2)\n","tc.matmul(x,y) # x @ y"]},{"cell_type":"markdown","id":"7bb78257","metadata":{"id":"7bb78257"},"source":["NumPy에서는 행렬곱 연산을 하는 함수가 두 개 있다. 바로 dot연산과 matmul 연산이다.두 함수는 2차원 배열 두개의 곱에 대해 동일한 행렬곱을 결과로 도출한다. 그러나 3차원 이상에서는 서로 다르게 동작한다. 이 두 함수의 차이가 궁금하다면 직접 검색하여 공부해보자."]},{"cell_type":"markdown","id":"1a3a1d7c","metadata":{"id":"1a3a1d7c"},"source":["다음으로 einsum()함수는 행렬 연산에 관한 다양한 함수들을 다 알지 못하더라도, 이 함수 하나만을 가지고 다양한 행렬 연산을 사용자가 직접 지정해줄 수 있는 함수이다. 이 함수의 원리는 아인슈타인 표기법을 따르는데, 아인슈타인 표기법에 대해 스스로 검색하여 공부해보면 Numpy와 PyTorch에서 einsum()함수를 사용하는 예시들을 쉽게 이해할 수 있을 것이다.\n","\n","아래의 예시들을 직접 실행해보며 einsum()함수의 유용함을 느껴보자, einsum()함수에 대해 완벽히 이해하지 못했더라도 괜찮다. 다만 앞으로 einsum()함수의 새로운 사용 예시를 보게 되더라도 낯설고 어렵게 느끼지 말고, 익숙하게 느끼길 바란다."]},{"cell_type":"code","execution_count":21,"id":"beabda70","metadata":{"id":"beabda70","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163492087,"user_tz":-540,"elapsed":375,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"41f4b1ca-9265-40cd-ae2a-8a042f64eac5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 0,  1,  2,  3,  4],\n","         [ 5,  6,  7,  8,  9],\n","         [10, 11, 12, 13, 14],\n","         [15, 16, 17, 18, 19],\n","         [20, 21, 22, 23, 24]]),\n"," tensor([[ 0,  1,  2],\n","         [ 3,  4,  5],\n","         [ 6,  7,  8],\n","         [ 9, 10, 11],\n","         [12, 13, 14]]),\n"," tensor([[  0,  -1,  -2],\n","         [ -3,  -4,  -5],\n","         [ -6,  -7,  -8],\n","         [ -9, -10, -11],\n","         [-12, -13, -14]]))"]},"metadata":{},"execution_count":21}],"source":["a = tc.arange(25).reshape(5,5)\n","b = tc.arange(15).reshape(5,3)\n","c = -tc.arange(15).reshape(5,3)\n","a, b, c"]},{"cell_type":"markdown","source":["i는 행, j는 열을 뜻함\n"],"metadata":{"id":"SO5CvLLnsh_n"},"id":"SO5CvLLnsh_n"},{"cell_type":"code","execution_count":22,"id":"c6166eb9","metadata":{"id":"c6166eb9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163519901,"user_tz":-540,"elapsed":367,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"82d0befc-06ff-41ad-f3db-2a3779a4bbcb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(60)"]},"metadata":{},"execution_count":22}],"source":["# a의 대각합\n","tc.einsum('ii',a)"]},{"cell_type":"code","execution_count":23,"id":"7e81572d","metadata":{"id":"7e81572d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163557431,"user_tz":-540,"elapsed":3,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"92528329-ee41-49a9-f12f-90627ca337ed"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([ 0,  6, 12, 18, 24])"]},"metadata":{},"execution_count":23}],"source":["# a의 대각원소\n","tc.einsum('ii->i',a)"]},{"cell_type":"code","execution_count":24,"id":"bc252f98","metadata":{"id":"bc252f98","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163594656,"user_tz":-540,"elapsed":377,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"4dd9a574-4c59-4a9f-ed81-f65be982c53f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[ 0,  3,  6,  9, 12],\n","        [ 1,  4,  7, 10, 13],\n","        [ 2,  5,  8, 11, 14]])"]},"metadata":{},"execution_count":24}],"source":["# b의 전치행렬\n","tc.einsum('ji',b)"]},{"cell_type":"code","execution_count":26,"id":"6d586edc","metadata":{"id":"6d586edc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163672764,"user_tz":-540,"elapsed":371,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"d2bfae7b-5650-46c5-8484-1838534326c5"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[ 90, 100, 110],\n","         [240, 275, 310],\n","         [390, 450, 510],\n","         [540, 625, 710],\n","         [690, 800, 910]]),\n"," tensor([[ 90, 100, 110],\n","         [240, 275, 310],\n","         [390, 450, 510],\n","         [540, 625, 710],\n","         [690, 800, 910]]))"]},"metadata":{},"execution_count":26}],"source":["# a와 b의 행렬곱 계산 (matmul과 결과가 동일함을 확인해보기)\n","tc.einsum('ij,jk->ik', a,b), tc.matmul(a,b)"]},{"cell_type":"code","execution_count":28,"id":"976de1a0","metadata":{"id":"976de1a0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163756668,"user_tz":-540,"elapsed":399,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"c4466ede-b7e1-4225-c7c2-92ff284280a9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([  -5,  -50, -149, -302, -509])"]},"metadata":{},"execution_count":28}],"source":["# 같은 모양의 텐서 b,c의 각 행끼리의 점곱을 계산\n","tc.einsum('ij,ij->i', b,c)"]},{"cell_type":"markdown","id":"50bdd8c5","metadata":{"id":"50bdd8c5"},"source":["#### 자동미분과 딥러닝을 위한 특수 함수"]},{"cell_type":"markdown","id":"6676ae0f","metadata":{"id":"6676ae0f"},"source":["PyTorch는 NumPy와 유사한 함수들 외에도 PyTorch만의 딥러닝을 위한 특수 함수들을 제공합니다. torch.nn 모듈에서는 딥러닝을 진행할 신경망을 구현하는 데 필요한 손실 함수(loss function), 활성 함수(activation function), 초기화 함수(initializer)의 대표적인 예시들을 제공합니다. 이러한 함수들에 대해서는 이번 실습에서는 다루지 않을 것이지만, 바로 다음 실습부터 꾸준히 여러 함수들이 등장할 예정입니다."]},{"cell_type":"markdown","id":"e1a37a44","metadata":{"id":"e1a37a44"},"source":["### Step 2 자동미분 실행하기"]},{"cell_type":"markdown","id":"d850545d","metadata":{"id":"d850545d"},"source":["이제 PyTorch 라이브러리의 핵심 기능인 자동미분에 대해 알아보자. PyTorch를 비롯한 대부분의 자동미분 라이브러리는 함수의 도함수(편도함수)를 직접 구하지 않는다. 그 대신 주어진 점(입력값)에서의 미분계수(편미분계수) 값을 구한다. 즉, 자동미분 라이브러리는 지정해준 점에서의 함수의 순간 기울기를 구하는 기능만을 갖고 있으며, 우리는 이를 이용하여 미분가능한 모든 함수의 모든 지점에서의 기울기를 구할 수 있다."]},{"cell_type":"markdown","id":"56abc047","metadata":{"id":"56abc047"},"source":["#### 텐서 객체의 '.backward()' 메서드"]},{"cell_type":"markdown","id":"0e4dd1f7","metadata":{"id":"0e4dd1f7"},"source":["PyTorch에서 자동미분을 호출하기 위해 필요한 유일한 방법은 Tensor.backward()이다. 다른 텐서로부터 계산한 텐서 F에 대해 F.backward()를 호출하면, PyTorch는 F가 의존하는 모든 텐서에 대해 F의 편미분계수를 계산하도록 지시한다. 이 편미분계수들은 각각의 텐서들의 .grad 속성에 Tensor로 저장된다. 이때 몇 가지 주의사항이 있다.\n","\n","1. requires_grad=True:\n","자동 미분을 추적하려면 텐서를 생성할 때 requires_grad=True로 설정해야 한다.\n","\n","2. backward() 호출:\n","Tensor.backward()를 호출하면 해당 텐서로부터 계산된 모든 텐서에 대해 그래디언트(기울기)를 계산합니다. backward()는 스칼라 값에 대해서만 호출할 수 있습니다. 만약 텐서가 스칼라가 아니라면, 적절한 축소 연산을 통해 스칼라로 변환한 후 backward()를 호출해야 한다 (예: sum())."]},{"cell_type":"markdown","id":"ee0edf3a","metadata":{"id":"ee0edf3a"},"source":["예를 들어 아래와 같이 x, y, z 텐서가 있고, x와 y의 함수로 정의된 f 텐서가 있는 상황에서의 편미분을 살펴보자."]},{"cell_type":"code","execution_count":29,"id":"8909fc52","metadata":{"id":"8909fc52","executionInfo":{"status":"ok","timestamp":1720163920830,"user_tz":-540,"elapsed":395,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["x = tc.tensor(2.0, requires_grad=True) #추적\n","y = tc.tensor(3.0, requires_grad=True)\n","z = tc.tensor(4.0, requires_grad=True)\n","f = x * y # tc.multiply(x, y)"]},{"cell_type":"markdown","id":"d9b04f19","metadata":{"id":"d9b04f19"},"source":["이 때, f.backward()를 호출하면 PyTorch가 f의 모든 편미분계수를 계산하도록 지시한다. 이는 역전파(backpropagation)라고 하는 컴퓨터가 빠르게 편미분계수를 계산할 수 있는 알고리즘을 사용하여 수행된다. 역전파 알고리즘은 딥러닝의 발전에서 빠질 수 없는 핵심적인 알고리즘이라 할 수 있는 것으로, 연쇄법칙(chain rule)에 기반한 알고리즘이다."]},{"cell_type":"code","execution_count":30,"id":"eff5c10e","metadata":{"id":"eff5c10e","executionInfo":{"status":"ok","timestamp":1720163933640,"user_tz":-540,"elapsed":414,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["f.backward() #편미분계수들을 계산해줌"]},{"cell_type":"markdown","id":"a891efdb","metadata":{"id":"a891efdb"},"source":["x와 y의 .grad() 속성을 살펴보면 $\\frac{d F}{d x}$와 $\\frac{d F}{dy}$의 값을 얻을 수 있다. .grad()는 텐서로 구해진다. z는 f가 의존하는 변수 텐서가 아니므로 .grad() 속성에 값이 없다."]},{"cell_type":"code","execution_count":31,"id":"692b2f01","metadata":{"id":"692b2f01","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163945088,"user_tz":-540,"elapsed":3,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"3e0d25dc-6a31-4ef3-c18e-ef3c43eb0729"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(3.)"]},"metadata":{},"execution_count":31}],"source":["x.grad"]},{"cell_type":"code","execution_count":32,"id":"208b6de2","metadata":{"id":"208b6de2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720163965065,"user_tz":-540,"elapsed":379,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"3d688484-d81c-44a6-8ffd-fbf35a9ffb58"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.)"]},"metadata":{},"execution_count":32}],"source":["y.grad"]},{"cell_type":"code","execution_count":34,"id":"7d5d2ed2","metadata":{"id":"7d5d2ed2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164011562,"user_tz":-540,"elapsed":389,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"041f5205-4e52-4c73-9407-6331b316ed10"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":34}],"source":["z.grad is None"]},{"cell_type":"markdown","id":"ab7cd692","metadata":{"id":"ab7cd692"},"source":["이번에는 x, y, 그리고 x와 y로부터 구해지는 f까지 세 텐서에 의존하는 텐서 F의 모든 편미분계수를 계산해보자. 즉, F(f(x, y), x, y)인 경우를 살펴볼 것이다."]},{"cell_type":"code","execution_count":35,"id":"2cebffb7","metadata":{"id":"2cebffb7","executionInfo":{"status":"ok","timestamp":1720164055377,"user_tz":-540,"elapsed":383,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["x = tc.tensor(2.0, requires_grad=True)\n","y = tc.tensor(3.0, requires_grad=True)\n","f = x * y\n","f.retain_grad()\n","F = f + x -2"]},{"cell_type":"code","execution_count":36,"id":"1a90c30f","metadata":{"id":"1a90c30f","executionInfo":{"status":"ok","timestamp":1720164060332,"user_tz":-540,"elapsed":2,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["F.backward()"]},{"cell_type":"markdown","id":"5cb35f93","metadata":{"id":"5cb35f93"},"source":["f의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial f}$의 값을 얻을 수 있다.\n","y의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial y} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial y}$의 값을 얻을 수 있다.\n","\n","마지막으로 x의 경우, t = x에 대해 F = f + t - 2로 쓸 수 있다. 이렇게 생각하고 x의 .grad() 속성을 살펴보면 $\\frac{\\partial F}{\\partial x} = \\frac{\\partial F}{\\partial f}\\frac{\\partial f}{\\partial x} + \\frac{\\partial F}{\\partial t}\\frac{\\partial t}{\\partial x}$의 값을 얻을 수 있다.\n","\n","주의사항으로 PyTorch에서 특정 텐서의 그래디언트를 계산하기 위해서는 그 텐서에 대해 직접적으로 requires_grad=True를 설정하고, 필요하다면 중간 텐서에 대해서도 retain_grad() 메소드를 호출해야 한다. retain_grad()는 중간 텐서의 그래디언트를 저장하도록 한다. f.retain_grad() 코드가 없다면 어떻게 실행되는지 확인해보는 것도 좋을 것이다."]},{"cell_type":"code","execution_count":37,"id":"17a4384e","metadata":{"id":"17a4384e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164066984,"user_tz":-540,"elapsed":4,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"f2dc8f45-72c7-405c-eff6-21744af8b1dd"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":37}],"source":["f.grad"]},{"cell_type":"code","execution_count":38,"id":"c3da1420","metadata":{"id":"c3da1420","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164071769,"user_tz":-540,"elapsed":403,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"0229c353-20ed-4b4a-d6bc-b89fcd4df8e0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2.)"]},"metadata":{},"execution_count":38}],"source":["y.grad"]},{"cell_type":"code","execution_count":39,"id":"f0f394a3","metadata":{"id":"f0f394a3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164075769,"user_tz":-540,"elapsed":356,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"2768268a-aef1-4772-e445-01821500e320"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.)"]},"metadata":{},"execution_count":39}],"source":["x.grad"]},{"cell_type":"markdown","id":"06825fb4","metadata":{"id":"06825fb4"},"source":["f와 F가 의존하는 모든 변수들이 PyTorch의 텐서로 저장되어 있었고, f와 F를 이루는 모든 수학적 연산이 PyTorch에서 제공하는 함수였기 때문에 PyTorch를 통해 F의 모든 편미분계수를 구할 수 있었다. 이렇게 구한 편미분계수들로부터 함수의 그래디언트를 이용하는 경사하강법을 쉽게 수행할 수 있다."]},{"cell_type":"markdown","id":"05aac9d3","metadata":{"id":"05aac9d3"},"source":["# 문제: 텐서 객체의 backward() 메서드 사용\n","\n","여러가지 수식으로 정의된 x에 대한 함수 F에 대해, x=2.5에서 $\\frac{d F}{d x}\\big|_{x=2.5}$를 구해보자."]},{"cell_type":"markdown","source":["# 1번 문제"],"metadata":{"id":"MAGBsn7xGd1k"},"id":"MAGBsn7xGd1k"},{"cell_type":"markdown","id":"f35f6a9d","metadata":{"id":"f35f6a9d"},"source":["1. $F(x)=x^2$"]},{"cell_type":"code","execution_count":40,"id":"1ad9f204","metadata":{"id":"1ad9f204","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164250379,"user_tz":-540,"elapsed":5,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"5a8ef33a-c00c-47b5-fd2d-176a6356ea2e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(5.)"]},"metadata":{},"execution_count":40}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","F = x**2\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 1번 문제 정답"],"metadata":{"id":"xfCuA6MxGEHh"},"id":"xfCuA6MxGEHh"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","F = x**2\n","F.backward()\n","x.grad"],"metadata":{"id":"hA-iU8diGMxo"},"id":"hA-iU8diGMxo","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["1번 문제 출력 결과 : tensor(5.)"],"metadata":{"id":"YIOuj1FMGPMw"},"id":"YIOuj1FMGPMw"},{"cell_type":"markdown","source":["# 2번 문제"],"metadata":{"id":"ekFW_3OnGSdU"},"id":"ekFW_3OnGSdU"},{"cell_type":"markdown","id":"7a5cd97f","metadata":{"id":"7a5cd97f"},"source":["2. $F(x)=\\cos{\\sqrt{x}}$"]},{"cell_type":"code","execution_count":42,"id":"f62fd0dd","metadata":{"id":"f62fd0dd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164311012,"user_tz":-540,"elapsed":382,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"3bfcd78c-e28f-4ccb-d3fe-dc6d9671d5b3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-0.3162)"]},"metadata":{},"execution_count":42}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","F = tc.cos(tc.sqrt(x))\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 2번 문제 정답"],"metadata":{"id":"G1rUUHZFGi-3"},"id":"G1rUUHZFGi-3"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","F = tc.cos(tc.sqrt(x))\n","F.backward()\n","x.grad"],"metadata":{"id":"4V1iRDD3GijE"},"id":"4V1iRDD3GijE","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2번 문제 출력 결과 : tensor(-0.3162)"],"metadata":{"id":"dIrwUZzyGibE"},"id":"dIrwUZzyGibE"},{"cell_type":"markdown","source":["# 3번 문제"],"metadata":{"id":"aBe8aYzXGr3G"},"id":"aBe8aYzXGr3G"},{"cell_type":"markdown","id":"f994e9f9","metadata":{"id":"f994e9f9"},"source":["3. $F(x)=2+3x-5x^2$"]},{"cell_type":"code","execution_count":43,"id":"9aba45f7","metadata":{"id":"9aba45f7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164343036,"user_tz":-540,"elapsed":410,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"43ff5636-ae0c-4a46-ee00-ed3b45543541"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-22.)"]},"metadata":{},"execution_count":43}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","F = 2 + 3*x - 5*x**2\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 3번 문제 정답"],"metadata":{"id":"b-l8ieGVGv3M"},"id":"b-l8ieGVGv3M"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","F = 2+3*x-5*x**2\n","F.backward()\n","x.grad"],"metadata":{"id":"mEgwk9LhGuT6"},"id":"mEgwk9LhGuT6","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["3번 문제 출력 결과 : tensor(-22.)"],"metadata":{"id":"gOabd2fPGul7"},"id":"gOabd2fPGul7"},{"cell_type":"markdown","source":["# 4번 문제"],"metadata":{"id":"0oTiFRY5G2tE"},"id":"0oTiFRY5G2tE"},{"cell_type":"markdown","id":"aa6ca763","metadata":{"id":"aa6ca763"},"source":["4. $F(x)=e^{lnx}$"]},{"cell_type":"code","execution_count":46,"id":"d028375e","metadata":{"id":"d028375e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164406426,"user_tz":-540,"elapsed":431,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"20ec7d6a-ee42-4e41-d462-5b2904ab169c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":46}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","F = tc.exp(tc.log(x))\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 4번 문제 정답"],"metadata":{"id":"rbGPZ_ydG53A"},"id":"rbGPZ_ydG53A"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","F = tc.exp(tc.log(x))\n","F.backward()\n","x.grad"],"metadata":{"id":"dLQKI_84G5Sa"},"id":"dLQKI_84G5Sa","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["4번 문제 출력 결과 : tensor(1.)"],"metadata":{"id":"G49bEx7jG5e4"},"id":"G49bEx7jG5e4"},{"cell_type":"markdown","source":["# 5번 문제"],"metadata":{"id":"9UFMZxcHHEX5"},"id":"9UFMZxcHHEX5"},{"cell_type":"markdown","id":"979502fa","metadata":{"id":"979502fa"},"source":["5. $F(x)=(2xf(x))^2-f(x), f(x)=x^2$"]},{"cell_type":"code","execution_count":48,"id":"e333cb51","metadata":{"id":"e333cb51","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164477914,"user_tz":-540,"elapsed":350,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"fbe1bc19-d2df-4f82-ca12-7a061528fa5a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(2338.7500)"]},"metadata":{},"execution_count":48}],"source":["# 여기에 코드 작성\n","x = tc.tensor(2.5, requires_grad=True)\n","f = x**2\n","F = (2*x*f)**2 - f\n","F.backward()\n","x.grad"]},{"cell_type":"markdown","source":["### 5번 문제 정답"],"metadata":{"id":"U0_bPo_AHGKV"},"id":"U0_bPo_AHGKV"},{"cell_type":"code","source":["x = tc.tensor(2.5, requires_grad=True)\n","f = x**2\n","F = (2*x*f)**2-f\n","F.backward()\n","x.grad"],"metadata":{"id":"PmQlhnDvHGbA"},"id":"PmQlhnDvHGbA","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5번 문제 출력 결과 : tensor(2338.7500)"],"metadata":{"id":"mfseKPKcHGwV"},"id":"mfseKPKcHGwV"},{"cell_type":"markdown","source":["# -"],"metadata":{"id":"1wT96P_lHMrw"},"id":"1wT96P_lHMrw"},{"cell_type":"markdown","id":"72ea07a0","metadata":{"id":"72ea07a0"},"source":["#### .grad 속성의 초기화"]},{"cell_type":"markdown","id":"0e8e4d75","metadata":{"id":"0e8e4d75"},"source":["경사하강법을 수행할 때, 텐서와 관련된 편미분계수를 반복적으로 구해야 한다. 따라서, 경사하강을 반복할 때마다 사이사이에 편미분계수를 폐기해야 한다."]},{"cell_type":"markdown","id":"6fce6da3","metadata":{"id":"6fce6da3"},"source":["backward()연산을 진행한 함수가 의존하는 텐서들 중 하나의 .grad 속성을 초기화하는 방법은 다음과 같이 두가지가 있다. 아래와 같은 상황을 생각해보자."]},{"cell_type":"code","execution_count":49,"id":"45b77985","metadata":{"id":"45b77985","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164495218,"user_tz":-540,"elapsed":4,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"6ce4e300-3ebf-41af-dee8-e6a7f7a04014"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(4.)"]},"metadata":{},"execution_count":49}],"source":["x = tc.tensor(2.0, requires_grad=True)\n","f = x**2\n","f.backward()\n","x.grad"]},{"cell_type":"markdown","id":"9b0e92ca","metadata":{"id":"9b0e92ca"},"source":["그래디언트를 초기화하지 않으면, 추가 연산 후 backward()를 호출해도 이전 값에 누적되지 않고 덮어쓴다."]},{"cell_type":"code","execution_count":50,"id":"c7a13d5b","metadata":{"id":"c7a13d5b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164559258,"user_tz":-540,"elapsed":369,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"0a9f216b-d854-474e-afdd-f6a5607a5c5d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(8.)"]},"metadata":{},"execution_count":50}],"source":["g = x**2\n","g.backward()\n","x.grad"]},{"cell_type":"markdown","id":"6477d424","metadata":{"id":"6477d424"},"source":["Tensor.grad를 호출하여 해당 텐서의 .grad 속성을 직접적으로 None으로 재설정할 수도 있다."]},{"cell_type":"code","execution_count":51,"id":"71cbc888","metadata":{"id":"71cbc888","executionInfo":{"status":"ok","timestamp":1720164580715,"user_tz":-540,"elapsed":493,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["x.grad = None"]},{"cell_type":"code","execution_count":52,"id":"0d3fb5eb","metadata":{"id":"0d3fb5eb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164586645,"user_tz":-540,"elapsed":367,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"8e231178-a0de-4aff-a21e-12c5c21f57cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":52}],"source":["x.grad is None"]},{"cell_type":"markdown","id":"6de8423c","metadata":{"id":"6de8423c"},"source":["#### PyTorch와 Numpy의 관계"]},{"cell_type":"markdown","id":"4133bbb6","metadata":{"id":"4133bbb6"},"source":["우리는 앞의 내용에서 PyTorch에서 NumPy의 다양한 수학함수들을 동일하게 정의해두었다는 것을 충분히 확인했다.\n","\n","PyTorch의 텐서 객체는 NumPy 배열과 비교했을 때 별로 새롭지 않다. 텐서 객체는 Numpy 배열에 대한 정보를 기본으로 가지고 있으며, 단지 배열이 관련된 수학적 연산들을 추적하는 추가 역할을 할 뿐이다. 수학적 연산에 대한 추적은 자동미분을 위해 추가된 역할이라고 볼 수 있다.\n","\n","이러한 관계성에 의해 우리는 텐서를 한꺼풀 벗겨내어 NumPy 배열을 얻을 수 있다. 다음의 텐서 x에 대해 NumPy 배열로 만드는 세 가지 방법을 확인해보자."]},{"cell_type":"markdown","id":"7I3HEHz_gIFV","metadata":{"id":"7I3HEHz_gIFV"},"source":["먼저, 기본 텐서의 경우 numpy()를 사용한다."]},{"cell_type":"code","execution_count":54,"id":"55472dc7","metadata":{"id":"55472dc7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164625522,"user_tz":-540,"elapsed":3,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"4b1b008b-a5f8-4131-d406-7dea168bd6ef"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.])"]},"metadata":{},"execution_count":54}],"source":["x = tc.tensor([0.0,1.0,2.0,3.0])\n","x"]},{"cell_type":"code","execution_count":55,"id":"1ef96a8b","metadata":{"id":"1ef96a8b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164629243,"user_tz":-540,"elapsed":401,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"0fab4381-620d-4e21-dc67-19e569dc5cb3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1., 2., 3.], dtype=float32)"]},"metadata":{},"execution_count":55}],"source":["x.numpy()"]},{"cell_type":"markdown","id":"9e22945e","metadata":{"id":"9e22945e"},"source":["두번째로, grad 정보가 포함된 경우 detach().numpy()를 사용한다."]},{"cell_type":"code","execution_count":56,"id":"ac022abd","metadata":{"id":"ac022abd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164632074,"user_tz":-540,"elapsed":352,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"50c8a79e-a56f-4b1a-d8d4-8a8aa0b3b404"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.], requires_grad=True)"]},"metadata":{},"execution_count":56}],"source":["x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True)\n","x"]},{"cell_type":"code","execution_count":57,"id":"38a70485","metadata":{"id":"38a70485","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164649417,"user_tz":-540,"elapsed":415,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"cbbbb119-0f5c-40f7-e16d-26283f4f2f35"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1., 2., 3.], dtype=float32)"]},"metadata":{},"execution_count":57}],"source":["x.detach().numpy()"]},{"cell_type":"markdown","id":"CqdEZEnAg9p9","metadata":{"id":"CqdEZEnAg9p9"},"source":["세번째로, gpu에 선언된 텐서의 경우 cpu().numpy()를 사용한다."]},{"cell_type":"code","execution_count":58,"id":"uwST0Z-7g596","metadata":{"id":"uwST0Z-7g596","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164716292,"user_tz":-540,"elapsed":950,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"907b8301-f1a0-48e3-9cd3-c08109b26800"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([0., 1., 2., 3.], device='cuda:0', grad_fn=<ToCopyBackward0>)"]},"metadata":{},"execution_count":58}],"source":["x = tc.tensor([0.0,1.0,2.0,3.0], requires_grad=True).cuda()\n","x"]},{"cell_type":"code","execution_count":59,"id":"2wax3zVOhMkf","metadata":{"id":"2wax3zVOhMkf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164727959,"user_tz":-540,"elapsed":384,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"87ac52e5-755a-4fd2-b00e-6da498418180"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0., 1., 2., 3.], dtype=float32)"]},"metadata":{},"execution_count":59}],"source":["x.cpu().detach().numpy()"]},{"cell_type":"markdown","id":"61fa582a","metadata":{"id":"61fa582a"},"source":["#### 편미분계수 계산 시 상수 텐서와 변수 텐서"]},{"cell_type":"markdown","id":"364ca3a4","metadata":{"id":"364ca3a4"},"source":["앞서 살펴본 머신러닝 모델에 대해 경사하강법을 진행하는 경우를 생각해보자.\n","\n","머신러닝 모델을 다음과 같이 정의할 때\n","\\begin{equation}\n","\\mathscr{L}\\big(w_1, ..., w_M ; (x_n, y_n)_{n=0}^{N-1}\\big)\n","\\end{equation}\n","\n","경사하강법을 수행하기 위해 우리는 $\\frac{d\\mathscr{L}}{dw_i}$를 각각의 $w_i$에 대해 계산해야 한다. 그러나, $\\frac{d\\mathscr{L}}{dx_i}$는 필요하지 않다. 특히, 입력 데이터셋이 크고 복잡해질수록, 필요없는 수많은 편미분계수를 일일이 계산하는 것은 쓸데없이 많은 비용이 드는 일이다.\n","\n","위에서 배운대로라면, PyTorch 텐서의 .backward() 메서드는 $\\mathscr{L}$를 이루는 모든 변수 텐서들에 대해 편미분계수를 계산한다. 따라서, 우리는 편미분계수 계산이 필요없는 데이터들을 변수 텐서가 아니라 상수 텐서로 표현함으로써 자동으로 .backward() 계산에서 배제되도록 할 것이다. 상수 텐서로 취급할 수 있는 방법을 알아보자."]},{"cell_type":"markdown","id":"667de722","metadata":{"id":"667de722"},"source":["PyTorch의 텐서 객체를 생성할 때 requires_grad=False를 사용하여 상수 텐서를 생성할 수 있다. requires_grad=False로 설정된 텐서는 그래디언트 계산에 포함되지 않는다. 기본값이 requires_grad=False이므로, 특별히 지정하지 않아도 된다."]},{"cell_type":"code","execution_count":null,"id":"28053219","metadata":{"id":"28053219"},"outputs":[],"source":["x = tc.tensor(1.)\n","y = tc.tensor(2., requires_grad=True)"]},{"cell_type":"code","execution_count":null,"id":"29c2bac7","metadata":{"id":"29c2bac7"},"outputs":[],"source":["F = x * y\n","print(F)\n","F.backward()\n","print(F)"]},{"cell_type":"code","execution_count":null,"id":"0ba47cc3","metadata":{"id":"0ba47cc3"},"outputs":[],"source":["F.grad"]},{"cell_type":"code","execution_count":null,"id":"6fb9cb00","metadata":{"id":"6fb9cb00"},"outputs":[],"source":["x.grad"]},{"cell_type":"code","execution_count":null,"id":"9355969c","metadata":{"id":"9355969c"},"outputs":[],"source":["y.grad is None"]},{"cell_type":"markdown","id":"47018679","metadata":{"id":"47018679"},"source":["추가적으로, 상수 텐서만으로 정의된 텐서의 경우에는 어떤 연산을 적용하더라도 상수 텐서가 생성된다. 따라서, 이렇게 얻은 상수 텐서에 대해서는 .backward() 메서드는 에러를 발생시킨다."]},{"cell_type":"code","execution_count":null,"id":"9be9f9c8","metadata":{"id":"9be9f9c8"},"outputs":[],"source":["x = tc.tensor(1.)\n","y = tc.tensor(2.)\n","F = x + y"]},{"cell_type":"code","execution_count":null,"id":"ae6005a5","metadata":{"id":"ae6005a5"},"outputs":[],"source":["F.backward()"]},{"cell_type":"code","execution_count":null,"id":"d2b85dc5","metadata":{"id":"d2b85dc5"},"outputs":[],"source":["F.grad is None"]},{"cell_type":"markdown","id":"b10bbdab","metadata":{"id":"b10bbdab"},"source":["### Step 3. 다차원 텐서의 자동미분 실행하기"]},{"cell_type":"markdown","id":"5989cb5b","metadata":{"id":"5989cb5b"},"source":["#### 다차원 텐서에 대해 정의된 함수에서의 자동미분"]},{"cell_type":"markdown","id":"95ac6652","metadata":{"id":"95ac6652"},"source":["지금까지는 하나의 스칼라 변수로 이루어진 0차원 텐서에 대해 정의된, 간단한 함수에 대해서만 자동미분을 실행해보았다. 그런데 텐서 객체는 다차원의 배열을 나타낼 수 있다. 따라서 다차원 텐서에 대해 정의된 함수에서 자동미분이 실행되는 방법을 알면 계산을 편리하게 할 수 있다.\n","\n","다차원 텐서와 관련된 .grad 속성을 어떻게 해석해야 할까? 한마디로 표현하면, 텐서의 각 원소를 스칼라 값 변수로 해석하면 된다. 즉, 다차원 텐서를 스칼라 변수들의 집합으로 보면 된다."]},{"cell_type":"markdown","id":"88c0e308","metadata":{"id":"88c0e308"},"source":["이렇게만 말해서는 이해가 잘 가지 않을 것이다. 다음과 같은 계산을 통해 자세히 알아보자."]},{"cell_type":"code","execution_count":null,"id":"c211a0be","metadata":{"id":"c211a0be"},"outputs":[],"source":["tensor = tc.tensor([2.0, 4.0, 8.0], requires_grad=True)\n","arr = tc.tensor([-1.0, 2.0, 0], requires_grad=True)\n","F = (arr * tensor ** 2).sum()\n","F.backward()"]},{"cell_type":"markdown","id":"b9a0d070","metadata":{"id":"b9a0d070"},"source":["위의 코드에서 정의된 함수 F를 풀어서 쓰면 $F = -1\\:(x_0)^2 + 2\\:(x_1)^2 + 0\\:(x_2)^2$이다. 그리고 다차원 텐서의 각 원소를 스칼라 값 변수로 해석한다는 것은, $\\mathrm{tensor} = [x_0, x_1, x_2]$로 보겠다는 뜻이다."]},{"cell_type":"markdown","id":"afbb87af","metadata":{"id":"afbb87af"},"source":["이때, tensor.grad에는 어떤 값이 저장되어야 타당할까? tensor의 각 스칼라 변수들로 편미분한 값들을 tensor와 같은 shape의 배열로 저장하면 좋을 것이다."]},{"cell_type":"markdown","id":"1fc1254d","metadata":{"id":"1fc1254d"},"source":["\\begin{align}\n","{\\nabla}F &= \\big[\\frac{\\partial F}{\\partial x_0},\\frac{\\partial F}{\\partial x_1},\\frac{\\partial F}{\\partial x_2}\\big]\\\\\n","&= \\big[-2x_0,\\:4x_1,\\:0x_2\\big]\\\\\n","{\\nabla}F\\big|_{x_0=2, x_1=4, x_2=8} &= \\big[-4,\\:16,\\:0\\big]\n","\\end{align}"]},{"cell_type":"markdown","id":"cd9e4e53","metadata":{"id":"cd9e4e53"},"source":["실제로 tensor.grad 는 tensor에 저장된 특정 값에서의 ${\\nabla}F$ 를 저장한다. 다음 코드를 실행하여 확인해보자."]},{"cell_type":"code","execution_count":null,"id":"ff494ccb","metadata":{"id":"ff494ccb"},"outputs":[],"source":["tensor.grad"]},{"cell_type":"markdown","id":"6637697f","metadata":{"id":"6637697f"},"source":["일반화하여 표현하면 다음과 같다. tensor의 각 원소는 스칼라 값 변수로 해석할 수 있고, tensor.grad에서 대응되는 위치의 요소는 해당 변수에 대한 미분계수이다.\n","\n","$\\text{tensor}[x_0, \\dots, x_{(N-1)}] \\rightarrow \\text{tensor.grad}[x_0, \\dots, x_{(N-1)}] = {\\nabla}F = \\big[\\frac{\\partial F}{\\partial x_0},\\dots,\\frac{\\partial F}{\\partial x_{(N-1)}}\\big]$"]},{"cell_type":"markdown","id":"9b333799","metadata":{"id":"9b333799"},"source":["#### 벡터화된 자동미분"]},{"cell_type":"markdown","id":"c4eca391","metadata":{"id":"c4eca391"},"source":["방금 다차원 텐서에 의해 정의된 스칼라 함수에 대한 자동미분에 대해 배웠다. 이번에는 스칼라 함수가 아닌, 벡터 함수에 대해 자동미분을 실행할 때는 어떻게 실행되는지 알아보자.\n","\n",".backward() 메서드를 호출한 최종 함수가 스칼라가 아니라 벡터 함수라면, PyTorch는 최종 함수를 스칼라로 다 합친 후에 역전파를 진행해야한다.\n","\n","이렇게 합친 $\\sum F$는 스칼라이기 때문에 $\\frac{\\partial (\\sum F)}{\\partial x_{i}}$ 또한 스칼라이다. 따라서 위에서 살펴본 바와 같이 tensor와 tensor.grad는 항상 같은 shape을 갖는다.\n","\n","이렇게만 말해서는 이해가 가지 않으니, 다음과 같은 계산을 통해 알아보자."]},{"cell_type":"code","execution_count":null,"id":"43a7cb94","metadata":{"id":"43a7cb94"},"outputs":[],"source":["tensor = tc.linspace(-5, 5, 20, requires_grad=True)\n","F = tensor ** 2  # shape-(20)인 텐서\n","F_sum = F.sum()\n","F_sum.backward()\n","#F.backward()\n","tensor.grad"]},{"cell_type":"markdown","id":"6d4fce29","metadata":{"id":"6d4fce29"},"source":["위의 코드에서 정의된 함수 F는 $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$이다. 그리고 PyTorch에서 F_sum.backward()를 실행할 때 이를 스칼라로 다 합친다는 것은, $\\sum {F} = x_0 ^2 + \\dots + x^2_{99}$로 합친 후 이에 대해 .backward()를 실행하겠다는 뜻이다."]},{"cell_type":"markdown","id":"2f3bc6ee","metadata":{"id":"2f3bc6ee"},"source":["그런데 여기서 의문이 생긴다. 다변수 벡터함수 $F$의 편미분 계수들을 구하기 위해서는 야코비 행렬을 구하는 게 합당해 보인다. 그런데 $\\sum F$에 대해 .backward()를 실행시키는 것은 매우 다른 결과를 불러온다.\n","\n","각 성분함수에 대한 편미분 계수들을 일일이 구하지 못하고, 대신 성분함수들의 합에 대한 편미분 계수 $\\frac{\\partial (F_0+F_1+ \\cdots + F_{N-1})}{\\partial x_i}$ 만을 구하게 된다."]},{"cell_type":"markdown","id":"85f872b3","metadata":{"id":"85f872b3"},"source":["왜 PyTorch에서는 자동미분 기능을 이렇게 구현한 것일까? 만약 다변수 벡터함수 의 각 성분함수들이 각각 독립인 입력 변수에 대해 정의되었다면, 즉 독립인 $x_0, x_1,\\cdots, x_{(N-1)}$ 에 대해 $F=[F_0(x_0), F_1(x_1), \\cdots, F_{N-1}(x_{(N-1)})]$ 로 정의되었다면 $\\sum F$에 대해 .backward()를 실행시키는 것은 의미있는 행위가 된다. 유효한 모든 편미분 계수를 $\\big[\\frac{\\partial F_{0}}{\\partial x_0},\\dots,\\frac{\\partial F_{N-1}}{\\partial x_{(N-1)}}\\big]$ 와 같이 구할 수 있게 되기 때문이다."]},{"cell_type":"markdown","id":"67aadde5","metadata":{"id":"67aadde5"},"source":["다시 위의 예시로 돌아가보자.  $F= \\big[x_0 ^2,\\ \\dots, \\; x^2_{99} \\big]$에 대해 .backward()를 실행시킨 것은  $\\sum{F} = x_0 ^2 + \\dots + x^2_{99}$에 대해 .backward()를 실행시킨 것과 같다. 그리고 이후에 입력 tensor $\\rm\\textbf{x} = \\big[ x_0, x_1,\\cdots, x_{(N-1)}\\big]$ 에 대한 tensor.grad를 구하면 입력 tensor $\\rm\\textbf{x}$와 shape이 동일한 ${\\nabla}(\\Sigma{{F}}) = \\big[2x_0,\\ \\dots, \\; 2x_{99} \\big]$ 가 구해진다."]},{"cell_type":"markdown","id":"94d7fc45","metadata":{"id":"94d7fc45"},"source":["이 계산은 결국, 100개의 독립적인 값들에 대해 함수 $f(x) = x ^ 2$ 의 편미분계수 값 ($\\frac{\\mathrm{d}f}{\\mathrm{d}x} = 2x$)을 한번에 계산한 것과 같았다. 따라서, PyTorch를 이용하여 독립적인 값들에 대한 성분함수로 이루어진 다변수 벡터 함수의 미분을 구하는 기능은, 여러 개의 독립적인 데이터를 하나의 텐서로 묶어서 동일한 계산을 한 번에 수행할 때 큰 이점이 있다. 신경망에 대해 배우고 본격적인 딥러닝에 대해 실습할 때 도움이 될 것이다."]},{"cell_type":"markdown","id":"b44d37d0","metadata":{"id":"b44d37d0"},"source":["### 문제: 도함수의 그래프 그리기\n","\n",".backward() 메서드를 이용하면 특정 점에서의 그래디언트만 구할 수 있고, 도함수의 식과 그래프는 알 수 없다. 그런데, 벡터화된 자동미분을 이용하면 여러 점에서의 편미분계수 값을 한번에 구할 수 있으므로, matplotlib을 통해 그래프를 찍을 수 있게 된다.\n","\n","1. 벡터화된 자동미분을 수행하는 다음의 함수를 완성해보자. matplotlib에 관한 실습1의 내용을 잘 떠올리면서 작성해보자. (주의: matplotlib에 데이터를 전달할 때는 torch의 텐서가 아닌, 널리 알려진 라이브러리인 NumPy의 배열을 사용하는 것이 좋습니다.)"]},{"cell_type":"markdown","source":[" $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$의 그래프와 그 도함수를 torch를 이용해서 그려보자."],"metadata":{"id":"n-UzYgKBZkV9"},"id":"n-UzYgKBZkV9"},{"cell_type":"code","execution_count":60,"id":"63b190cf","metadata":{"id":"63b190cf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720164932669,"user_tz":-540,"elapsed":5,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"a8e337dd-3874-4cde-921a-d38b1347f058"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([ 0.0000,  0.0020,  0.0040,  ..., -0.0273, -0.0273, -0.0273],\n","        grad_fn=<MulBackward0>),\n"," tensor([2.0000, 1.9987, 1.9973,  ..., 0.0021, 0.0022, 0.0024]))"]},"metadata":{},"execution_count":60}],"source":["x = tc.linspace(0, 10, 10000, requires_grad = True)\n","y = tc.sin(2*x)*tc.cos(x)*tc.exp(-x/3)\n","y_sum = y.sum()\n","y_sum.backward()\n","y, x.grad"]},{"cell_type":"code","execution_count":63,"id":"a956957d","metadata":{"id":"a956957d","executionInfo":{"status":"ok","timestamp":1720165000607,"user_tz":-540,"elapsed":453,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def plot_func_and_deriv(x, func):\n","    \"\"\"\n","    함수 func(x)와 도함수 dfunc/dx를 같은 축(axis) 상에 그리는 함수\n","\n","    매개변수 (Parameters)\n","    ----------\n","    x : PyTorch.Tensor, shape-(N,)\n","        함수 func(x)와 도함수 dfunc/dx를 그리는 x의 정의역\n","\n","    func: Callable[[Tensor], Tensor]\n","        x에 대한 일변수 함수\n","\n","    반환 값 (Returns)\n","    -------\n","    Tuple[Figure, Axis]\n","        matplotlib로 그래프를 그리기 위한 fig와 ax\n","    \"\"\"\n","    x = tc.tensor(x, requires_grad=True)\n","    y = func(x)\n","    y.sum().backward()\n","\n","    # 여기에 코드 작성\n","    fig, ax = plt.subplots()\n","    ax.plot(x.detach().numpy(), y.detach().numpy(), c=\"red\")\n","    ax.plot(x.detach().numpy(), x.grad.detach().numpy(), c=\"blue\")\n","    ax.grid(True)\n","\n","    return fig, ax"]},{"cell_type":"markdown","id":"6565d15f","metadata":{"id":"6565d15f"},"source":["2. 이제 위에서 작성한 함수를 이용하여 구간 $[0, 10]$를 균등하게 10,000개로 나눈 정의역에 대해 함수 $f(x) = \\sin{(2x)}\\; \\cos{(x)}\\; e^{-x/3}$와 그 도함수의 그래프를 그려보자."]},{"cell_type":"code","execution_count":64,"id":"72733202","metadata":{"id":"72733202","executionInfo":{"status":"ok","timestamp":1720165003793,"user_tz":-540,"elapsed":411,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["def f(x):\n","    # 여기에 코드 작성\n","    return tc.sin(2*x)*tc.cos(x)*tc.exp(-x/3)*100"]},{"cell_type":"code","execution_count":65,"id":"7c5f677e","metadata":{"id":"7c5f677e","colab":{"base_uri":"https://localhost:8080/","height":486},"executionInfo":{"status":"ok","timestamp":1720165005907,"user_tz":-540,"elapsed":524,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"60860188-208a-4dc7-b5cf-321be084f18e"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-63-a5175a552b13>:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  x = tc.tensor(x, requires_grad=True)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAjMAAAGdCAYAAADnrPLBAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABkrklEQVR4nO3dd1xV9f8H8Ndl40BFBURx771SUdNKxZUNbVhWVqZlmqthNvxlS7My02wPG5pW37KyoeS2cIvmnuUENwgKXLif3x9vDxcSBe49497L6/l48DgXuPecDx8u3Nf9TJtSSoGIiIjIS/lZXQAiIiIidzDMEBERkVdjmCEiIiKvxjBDREREXo1hhoiIiLwawwwRERF5NYYZIiIi8moMM0REROTVAqwugBkcDgeOHTuGsmXLwmazWV0cIiIiKgKlFM6fP4/o6Gj4+V25/aVEhJljx44hJibG6mIQERGRCw4fPoxq1apd8fslIsyULVsWgFRGWFiYbue12+1YvHgx4uLiEBgYqNt5KT/Ws3lY1+ZgPZuD9WwOI+s5NTUVMTExua/jV1IiwozWtRQWFqZ7mClVqhTCwsL4h2Ig1rN5WNfmYD2bg/VsDjPqubAhIhwATERERF6NYYaIiIi8GsMMEREReTWGGSIiIvJqDDNERETk1RhmiIiIyKsxzBAREZFXY5ghIiIir8YwQ0RERF7N0DAzefJkXHPNNShbtiwiIiJwyy23YPfu3fnuk5GRgREjRqBixYooU6YMBgwYgOTk5Hz3OXToEPr27YtSpUohIiICTz75JLKzs40sOhEREXkJQ8PMihUrMGLECKxZswbx8fGw2+2Ii4tDenp67n3Gjh2Ln3/+Gd9++y1WrFiBY8eOoX///rnfz8nJQd++fZGVlYW//voLn3/+OWbPno2JEycaWXQiIiLyEobuzfT777/n+3z27NmIiIjAxo0b0aVLF6SkpOCTTz7B3LlzccMNNwAAPvvsMzRq1Ahr1qxBhw4dsHjxYuzYsQN//PEHIiMj0bJlS7z00ksYP348XnjhBQQFBRn5IxAREZGHM3WjyZSUFABAeHg4AGDjxo2w2+3o3r177n0aNmyI6tWrIyEhAR06dEBCQgKaNWuGyMjI3Pv07NkTw4cPx/bt29GqVavLrpOZmYnMzMzcz1NTUwHIZlh2u12Xn0Up4OOPHZgzpy2aN7fjKjuTk5u035levzu6Mta1OVjP5mA9m8PIei7qOU0LMw6HA2PGjEGnTp3QtGlTAEBSUhKCgoJQvnz5fPeNjIxEUlJS7n3yBhnt+9r3CjJ58mRMmjTpsq8vXrwYpUqVcvdHyfXGG11x8GBVzJy5AV27HtXtvFSw+Ph4q4tQYrCuzcF6Ngfr2RxG1POFCxeKdD/TwsyIESOwbds2rF692vBrTZgwAePGjcv9PDU1FTExMYiLi0NYWJhu11m+HJg+HTh5siX69Gmh23kpP7vdjvj4ePTo0cOw7eVJsK7NwXo2B+vZHEbWs9azUhhTwszIkSOxcOFCrFy5EtXy9MdERUUhKysL586dy9c6k5ycjKioqNz7rFu3Lt/5tNlO2n3+Kzg4GMHBwZd9PTAwUNeKjovLxvTpwLJl/ggIsMFm0+3UVAC9f390Zaxrc7CezcF6NocR9VzU8xk6m0kphZEjR+KHH37A0qVLUatWrXzfb9OmDQIDA7FkyZLcr+3evRuHDh1CbGwsACA2NhZ///03Tpw4kXuf+Ph4hIWFoXHjxkYWv1CdOikEBubg6FEbdu2ytChEREQllqEtMyNGjMDcuXPx448/omzZsrljXMqVK4fQ0FCUK1cOQ4YMwbhx4xAeHo6wsDA89thjiI2NRYcOHQAAcXFxaNy4Me69915MnToVSUlJeO655zBixIgCW1/MFBoKNGp0Blu3Vsby5UCjRpYWh4iIqEQytGXmvffeQ0pKCq677jpUqVIl92P+/Pm593nrrbdw4403YsCAAejSpQuioqLw/fff537f398fCxcuhL+/P2JjY3HPPffgvvvuw4svvmhk0YusUaPTAICEBIsLQkREVEIZ2jKjlCr0PiEhIZg1axZmzZp1xfvUqFEDv/76q55F002DBmcBMMwQERFZhXszual+fQkz+/YBJ09aXBgiIqISiGHGTWXK2NGwobRArVljcWGIiIhKIIYZHXTowDBDRERkFYYZHbRpI2EmMdHachAREZVEDDM6aNGCYYaIiMgqDDM6aNpUwWYDjh0D8qztR0RERCZgmNFBmTJAvXpye8sWa8tCRERU0jDM6KTFpX0m2dVERERkLoYZnbRsKcfNmy0tBhERUYnDMKMTLcywm4mIiMhcDDM6adJEjnv3Ana7tWUhIiIqSRhmdBITA5QqJUFm/36rS0NERFRyMMzoxM8PaNRIbu/caW1ZiIiIShKGGR0xzBAREZmPYUZHDDNERETmY5jREcMMERGR+RhmdNS4sRx37QIcDmvLQkREVFIwzOioTh0gMBBITwcOH7a6NERERCUDw4yOAgKcezTt2mVtWYiIiEoKhhmd1a8vx337rC0HERFRScEwo7O6deXIMENERGQOhhmdMcwQERGZi2FGZ3XqyJFhhoiIyBwMMzrTWmYOHABycqwtCxERUUnAMKOzmBiZnp2VBRw9anVpiIiIfB/DjM78/YHateU2u5qIiIiMxzBjAA4CJiIiMg/DjAEYZoiIiMzDMGMAhhkiIiLzMMwYQAsze/daWw4iIqKSgGHGANpaMwcPAkpZWxYiIiJfxzBjgOrV5ZieDpw+bW1ZiIiIfB3DjAGCg4HoaLn9zz+WFoWIiMjnMcwYpGZNOTLMEBERGYthxiAMM0REROZgmDFIjRpyZJghIiIyFsOMQdgyQ0REZA6GGYMwzBAREZmDYcYgecMM15ohIiIyDsOMQfKuNXPmjLVlISIi8mUMMwYJCQGqVJHb7GoiIiIyDsOMgThuhoiIyHgMMwZimCEiIjIew4yBGGaIiIiMxzBjIC6cR0REZDyGGQPFxMjx8GFry0FEROTLDA0zK1euRL9+/RAdHQ2bzYYFCxbk+/79998Pm82W76NXr1757nPmzBkMGjQIYWFhKF++PIYMGYK0tDQji60bhhkiIiLjGRpm0tPT0aJFC8yaNeuK9+nVqxeOHz+e+/H111/n+/6gQYOwfft2xMfHY+HChVi5ciWGDRtmZLF1o4WZM2eACxesLQsREZGvCjDy5L1790bv3r2vep/g4GBERUUV+L2dO3fi999/x/r169G2bVsAwMyZM9GnTx+88cYbiI6O1r3MeipXDihTBkhLA44cAerXt7pEREREvsfQMFMUy5cvR0REBCpUqIAbbrgBL7/8MipWrAgASEhIQPny5XODDAB0794dfn5+WLt2LW699dYCz5mZmYnMzMzcz1NTUwEAdrsddrtdt7Jr57raOatWDcDu3TYcPJiNWrW4r4ErilLPpA/WtTlYz+ZgPZvDyHou6jktDTO9evVC//79UatWLezfvx/PPPMMevfujYSEBPj7+yMpKQkRERH5HhMQEIDw8HAkJSVd8byTJ0/GpEmTLvv64sWLUapUKd1/jvj4+Ct+LyQkFkAEfvllKzIyOHjGHVerZ9IX69ocrGdzsJ7NYUQ9XyjiGA1Lw8zAgQNzbzdr1gzNmzdHnTp1sHz5cnTr1s3l806YMAHjxo3L/Tw1NRUxMTGIi4tDWFiYW2XOy263Iz4+Hj169EBgYGCB91mwwB9btgAVK7ZAnz7NdLt2SVKUeiZ9sK7NwXo2B+vZHEbWs9azUhjLu5nyql27NipVqoR9+/ahW7duiIqKwokTJ/LdJzs7G2fOnLniOBtAxuEEBwdf9vXAwEBDntBXO6+21syxY/4IDPTX/doliVG/P7oc69ocrGdzsJ7NYUQ9F/V8HrXOzJEjR3D69GlUubRDY2xsLM6dO4eNGzfm3mfp0qVwOBxo3769VcUslmrV5Mjp2URERMYwtGUmLS0N+/bty/384MGDSExMRHh4OMLDwzFp0iQMGDAAUVFR2L9/P5566inUrVsXPXv2BAA0atQIvXr1wtChQ/H+++/Dbrdj5MiRGDhwoMfPZNJo07OPHLG2HERERL7K0JaZDRs2oFWrVmjVqhUAYNy4cWjVqhUmTpwIf39/bN26FTfddBPq16+PIUOGoE2bNli1alW+LqI5c+agYcOG6NatG/r06YPOnTvjww8/NLLYuuLCeURERMYytGXmuuuug1JXno68aNGiQs8RHh6OuXPn6lksU2lh5tw5WW+mTBlLi0NERORzPGrMjC8qWxbQJlCxdYaIiEh/DDMm4LgZIiIi4zDMmIDjZoiIiIzDMGMCTs8mIiIyDsOMCdjNREREZByGGROwm4mIiMg4DDMm0LqZjh61thxERES+iGHGBNpixceOWVsOIiIiX8QwYwItzJw5A1y8aG1ZiIiIfA3DjAnKlwdCQ+X28eOWFoWIiMjnMMyYwGZjVxMREZFRGGZMwjBDRERkDIYZk2hhhjOaiIiI9MUwY5KqVeXIlhkiIiJ9McyYhN1MRERExmCYMQnDDBERkTEYZkzCMTNERETGYJgxSd6WGaWsLQsREZEvYZgxiRZm0tOB8+etLQsREZEvYZgxSenSQLlycpvjZoiIiPTDMGMijpshIiLSH8OMiTijiYiISH8MMybiwnlERET6Y5gxEVtmiIiI9McwYyKOmSEiItIfw4yJ2DJDRESkP4YZE3HMDBERkf4YZkzEVYCJiIj0xzBjoqgoOdrtwOnT1paFiIjIVzDMmCgoCKhcWW5zEDAREZE+GGZMxkHARERE+mKYMZnW1ZSUZG05iIiIfAXDjMmqVJEjwwwREZE+GGZMprXMHD9ubTmIiIh8BcOMydgyQ0REpC+GGZOxZYaIiEhfDDMmY8sMERGRvhhmTMbZTERERPpimDGZFmbS0uSDiIiI3MMwY7KyZYHSpeU2W2eIiIjcxzBjAQ4CJiIi0g/DjAU4CJiIiEg/DDMWYMsMERGRfhhmLMCWGSIiIv0wzFiA07OJiIj0Y2iYWblyJfr164fo6GjYbDYsWLAg3/eVUpg4cSKqVKmC0NBQdO/eHXv37s13nzNnzmDQoEEICwtD+fLlMWTIEKR5+ZxmrWWG3UxERETuMzTMpKeno0WLFpg1a1aB3586dSpmzJiB999/H2vXrkXp0qXRs2dPZGRk5N5n0KBB2L59O+Lj47Fw4UKsXLkSw4YNM7LYhmPLDBERkX4CjDx579690bt37wK/p5TC9OnT8dxzz+Hmm28GAHzxxReIjIzEggULMHDgQOzcuRO///471q9fj7Zt2wIAZs6ciT59+uCNN95AdHS0kcU3DAcAExER6cfQMHM1Bw8eRFJSErp37577tXLlyqF9+/ZISEjAwIEDkZCQgPLly+cGGQDo3r07/Pz8sHbtWtx6660FnjszMxOZmZm5n6empgIA7HY77Ha7bj+Ddq7inrNSJQAIxMmTChkZ2fD3161IPsnVeqbiY12bg/VsDtazOYys56Ke07Iwk3SpjyUyMjLf1yMjI3O/l5SUhIiIiHzfDwgIQHh4eO59CjJ58mRMmjTpsq8vXrwYpUqVcrfol4mPjy/W/XNyAD+/m+Bw2PD110sQHp5Z+IOo2PVMrmNdm4P1bA7WszmMqOcLFy4U6X6WhRkjTZgwAePGjcv9PDU1FTExMYiLi0NYWJhu17Hb7YiPj0ePHj0QGBhYrMdGRMiYmSZNuqFVK92K5JPcqWcqHta1OVjP5mA9m8PIetZ6VgpjWZiJujRwJDk5GVW06T2XPm/ZsmXufU6cOJHvcdnZ2Thz5kzu4wsSHByM4ODgy74eGBhoyBPalfNGRUmYOXUqEPwbKxqjfn90Oda1OVjP5mA9m8OIei7q+SxbZ6ZWrVqIiorCkiVLcr+WmpqKtWvXIjY2FgAQGxuLc+fOYePGjbn3Wbp0KRwOB9q3b296mfXEhfOIiIj0YWjLTFpaGvbt25f7+cGDB5GYmIjw8HBUr14dY8aMwcsvv4x69eqhVq1aeP755xEdHY1bbrkFANCoUSP06tULQ4cOxfvvvw+73Y6RI0di4MCBXjuTScPp2URERPowNMxs2LAB119/fe7n2jiWwYMHY/bs2XjqqaeQnp6OYcOG4dy5c+jcuTN+//13hISE5D5mzpw5GDlyJLp16wY/Pz8MGDAAM2bMMLLYpuDCeURERPowNMxcd911UEpd8fs2mw0vvvgiXnzxxSveJzw8HHPnzjWieJZiywwREZE+uDeTRbhwHhERkT4YZizCAcBERET6YJixSN6Wmav0xBEREVEhGGYsooWZCxcAL98EnIiIyFIMMxYpU0Y+AHY1ERERuYNhxkKcnk1EROQ+hhkLcXo2ERGR+xhmLMSWGSIiIvcxzFiIa80QERG5j2HGQlqYSU62thxERETejGHGQhwzQ0RE5D6GGQsxzBAREbmPYcZC3NKAiIjIfQwzFtJaZk6cAHJyrC0LERGRt2KYsVDlyoCfH+BwACdPWl0aIiIi78QwYyF/fwk0ALuaiIiIXMUwYzEOAiYiInIPw4zFGGaIiIjcwzBjMYYZIiIi9zDMWIxhhoiIyD0MMxZjmCEiInIPw4zFuHAeERGRexhmLMaWGSIiIvcwzFiMYYaIiMg9DDMW08JMSgpw8aK1ZSEiIvJGDDMWCwsDQkLkNltniIiIio9hxmI2G7uaiIiI3MEw4wEYZoiIiFzHMOMBGGaIiIhcxzDjARhmiIiIXMcw4wG4cB4REZHrGGY8AFtmiIiIXMcw4wEYZoiIiFwXYHUByBlmjh/P88W0NOCjj4BffwWOHQPCw4HrrweGDgViYiwpJxERkSdimPEAeVtmlAJsixcB990HnDiR/46rVwOvvw5MmgQ88QTgx4Y1IiIivhp6gMhIOdrtwNlZc4HevSXI1K0LvP02sGQJ8OmnQKdOQEYGMH48MHAgkJlpbcGJiIg8AFtmPEBwMFChAnD2LJA06lWEKwU8+CAwa5ZzrwMAuP9+4OOPgREjgG+/BXJygPnzgQD+GomIqORiy4yHiKqYBQBIUhHAsGESWvIGGUD2Phg6VMbRBAUB338PjBtnQWmJiIg8B8OMJ3A4EHViKwAgqX5XaZGx2a58/+7dgblz5fbMmcA335hQSCIiIs/EMOMJPvkEVVJ3AwCS7hhVtG6jAQOAp5+W2w89BBw6ZGABrbNuHTB0qD+eeaYThgzxx5o1VpeIiIg8DcOM1c6cASZMQBRkkZmkzApFf+xLLwEdOwLnzwPDh8tUKB/yyitAhw7A55/7YceOSvjySz/ExgLPP+9zPyoREbmBYcZq06YBp08j6tKMpmItnBcQIGNrgoJkHM28eYYU0QpvvAE895yEloEDHRg7dgPuuccBAHj5ZclxREREAMOMtc6cAWbMAABE3dkVwH8WziuKRo3kVR+QtWfS03UsoDUSEpw9aFOnAl98kYOuXY/i009z8M478vX/+z9g0SLrykhERJ6DYcZKb78tXUTNmiGqT2sALm5p8OSTQM2aslLwm2/qWkSzZWfLEKCcHODuuyWf5TVihHwAcr/UVPPLSEREnoVhxioZGTJrCQCefx5R0fKrcCnMhIQAU6bI7alTXWje8RyffALs2CG7N7zzTsGTul57DahTBzhyRLqjiIioZLM8zLzwwguw2Wz5Pho2bJj7/YyMDIwYMQIVK1ZEmTJlMGDAACQnJ1tYYp3Mnw+cPi37LN16a+6WBqdOyUrAxXbHHTJaNj1dBpV4oaws2akBAF54QRYSLEjp0hJoABlyxA06iYhKNsvDDAA0adIEx48fz/1YvXp17vfGjh2Ln3/+Gd9++y1WrFiBY8eOoX///haWVidaq8zw4UBAACpWBPz95Uv/3ZKpSGw2Z+vMxx9Ls4WXmTdPGpWio4GHH776ffv3B9q1k+x2adgRERGVUB4RZgICAhAVFZX7UalSJQBASkoKPvnkE0ybNg033HAD2rRpg88++wx//fUX1njzgiMbNgDr18sspIceAiB7Rka6MqMpr65dgS5dpIlDa7rwEko5h/s89phUzdXYbMCECXL7/fd9YtwzERG5yCM29dm7dy+io6MREhKC2NhYTJ48GdWrV8fGjRtht9vRvXv33Ps2bNgQ1atXR0JCAjp06FDg+TIzM5GZZxPG1EujRO12O+wu9eEUTDtXcc/p98kn8Afg6N8fOeXL5/YrRUX549gxPxw5ko3mzV1bSMX27LMIWLkS6qOPkP3EE9LM4QXWrLFh69YAlCql8MAD2fm62q5Uz716AXXqBGD/fhs+/TQHjzziMLPIPsnV5zQVD+vZHKxncxhZz0U9p+Vhpn379pg9ezYaNGiA48ePY9KkSbj22muxbds2JCUlISgoCOXLl8/3mMjISCRdpfli8uTJmKQNvshj8eLFKFWqlN4/AuLj44t8X5vdjp5z5sAfwJoGDXDy119zv+fn1x5AFOLj/wbg4oq+SqFzo0aouHMn/h01CtsffNC185js/febA6iF9u0PY82azQXep6B6vv762ti/vxneeus8qldfYXApS47iPKfJdaxnc7CezWFEPV+4cKFI97Mp5VlrqZ47dw41atTAtGnTEBoaigceeCBfKwsAtGvXDtdffz1eu0JXSkEtMzExMTh16hTCwsJ0K6vdbkd8fDx69OiBwMDAIj3GtnAhAvr3h4qKQvaBA/m2Lnj4YX989pkfJk3KwYQJrrcy2BYtQkC/flBlysg1/hMGPU1mJhATE4Bz52z4/fds3HBD/qfk1er5zBmgevUAZGXZsG6dHS1bmlhwH+TKc5qKj/VsDtazOYys59TUVFSqVAkpKSlXff22vGXmv8qXL4/69etj37596NGjB7KysnDu3Ll8rTPJycmI0qb/FCA4OBjBwcGXfT0wMNCQJ3SxzntplV7bXXchMDQ037e0HqETJ/wRGOjveoH69gWaNIFt+3YEzp4t69B4sJ9+As6dA6pVA7p3D8gdCP1fBdVzZCRwyy2y1+ZXXwXimmsML26JYNTfCuXHejYH69kcRtRzUc/nEQOA80pLS8P+/ftRpUoVtGnTBoGBgViyZEnu93fv3o1Dhw4hNjbWwlK6KDVVXrkB4J57Lvu2ls/cnmpsswHjxsntGTNcnOttHm3T70GDcMUgczX33y/HOXM8/kclIiIDWB5mnnjiCaxYsQL//PMP/vrrL9x6663w9/fHXXfdhXLlymHIkCEYN24cli1bho0bN+KBBx5AbGzsFQf/erRff5XF8urXB1q1uuzbuoUZQJJBZKRM0f72Wx1OaIzMTOC33+T2rbe6do64OCAiQpbtWb5ct6IREZGXsDzMHDlyBHfddRcaNGiAO+64AxUrVsSaNWtQuXJlAMBbb72FG2+8EQMGDECXLl0QFRWF77//3uJSu2jBAjn271/g0ra6hpngYOe6/2++6bHbTC9fLjs6VKkCl7uI/P2lqwkAvvtOr5IREZG3sDzMzJs3D8eOHUNmZiaOHDmCefPmoU6dOrnfDwkJwaxZs3DmzBmkp6fj+++/v+p4GY+VmSktM4Dzlfc/dA0zgCzIFxoKbNoE5FmI0JP8+KMcb7pJ1tpx1W23yXHBAtnXiYiISg7Lw0yJsXSpNEFER1+xCUILM+npQFqaDtesVEm6mwDg3Xd1OKG+lHKGmZtvdu9c110n2x+cOOGxuY2IiAzCMGMWrYvp5puv2ARRpox8ADq2zjz6qBz/9z+P28Ro2zbZ6LtUKeCGG9w7V2CgMxB5ay8kERG5hmHGDA6HswniCl1MGt27mlq1AmJjZZrPRx/pdFJ9/PGHHLt2lSE+7tLCTJ51CImIqARgmDHDpk1AcjIQFib9IVehe5gBnAOBP/gAyM7W8cTu0cJMnt0q3NKtm7TQ7NsH7N2rzzmJiMjzMcyYYdEiOXbrVugOioaEmdtuAypXBo4eda5zY7GsLGDFpd0H9AozZcsCnTvLbW26NxER+T6GGTNoYSYurtC7amHm+HEdrx8cnLs7N2bN0vHErlu7VgY6R0QATZvqd97eveXIMENEVHIwzBgtNRVISJDbPXsWendDWmYA4OGHZeDx0qXAzp06n7z4tC6mbt3cm5L9X1qYWb4cuHhRv/MSEZHnYpgx2tKlMk6lXj2gVq1C725YmKlRA7jxRrn93ns6n7z4li6VY7du+p63SRMgJkYWWuZqwEREJQPDjNG0LqYitMoABoYZwDkQ+PPPdVrIxjUZGcC6dXK7a1d9z22zOXvztMBERES+jWHGSEoVO8xUqSJHQ8JM9+5A3brS9TV3rgEXKJqNG2UAcEQEkGexZ91oa9YwzLgvI0M2Ah02DOjTB7jrLmD6dJ3HdBERuYlhxkj79wMHD8p84UKmZGu0lpnkZFmeRld+frLFASADgS3ar+nPP+XYqVOBW1S57frr5bh5M3D27H++qRTw778SMr/9VmZ37djhUVPWPcWPP8qeqHfeKUsU/fYbMG8eMHYsULOmbMx+4YLVpSQiYpgx1rJlcuzQwbm0byEqV5YX+Jwc2QVad/ffD4SEAFu3OgcmmyxvmDFClSpAgwaSW1auvPTF48eBZ5+VsUs1awK9egF33CEr7TVpIjuMP/QQ8PffxhTKizgcwMSJfrjlFuDwYdmB44kngI8/BiZPljUYs7KAt94C2rQBDhywusREVNIxzBhJW0iliK0ygDTiVKoktw3pagoPl74CwJL9mpQC/vpLbhsVZoA8XU2L7MCECRJgXn1VWssCAyXAdOkir8ZlygBnzgCffAI0bw4MHOhxWz+Y6fPPm2DKFH8A0vqydy/w+uvAkCHA00/L7++XX4CqVYFduySrb9tmcaGJqERjmDGKUs7pNMUIM4DBg4AB535N334rOzOaaM8e4NQpaRxq3dq462hdTcs+3g9MmSJNCZ06AfPnS3DZtk3C5oYN0he1dKm01Nhscp9GjZxbUJQgM2f64ccf6wIAPvwQePNN2Tvrv/r0Adavl90yTp6UQdcHD5pcWCKiSxhmjHLggKy4Gxgob12LwZCF8/Jq21Z27s7KAj791KCLFEzb0bpdu0IXQ3bLdUfnAAD+tjfEyaotZWzM6tUSWP7b5RcQIOln/nwZndy6NXDunOyjNWmSZWOLzLZ+PTB+vPxLePXVHAwdevX7V6ki6wU1bSrP1b59LZ0kR0QlGMOMUbRWmfbtC35rexWGt8wAztaZ99+XATomMbyLSSng1VdReew9aIatAIDlr6wG+vUr2uNbtQLWrAEee0w+f+EFYNQoA0Zje5YLF6T3MTvbho4dj+Lxx4v284aHy1jqKlVkLcZhw0pM9iMiD8IwYxRtvIwLC6mYEmbuvFNeif7919S1/7X1Zdq3N+DkSgHPPCMDfQF0bStTbVZvKl288wQGAjNmyOKCNhvwzjuyRo8Pv0prw4liYhQefXRLsWaZRUdLj2VAAPD116Y39hERMcwYwo3xMoBJYSY0FHjwQblt0kDg9HSZBQ1IL5fupkyRDwB48010ely697TZU8X2yCPA7Nkypf3994GXX9almJ5GG+ALANOm5aBMGXuxz9GpE/DKK3J73DjgyBEdC0hEVAiGGSP884/MaQ0IkHmsxWTownl5PfKIHH//Xd6WG2zzZumtiY6WD119+qm0ygCyqtu4cbldWYmJbozluO8+aZkBgIkTJdz4mKeekuFTvXsDN93keuvT44/L8LDUVHY3EZG5GGaMoLXKtGsHlC5mFwdMapkBZPndXr3kVeeDDwy+mEwcAmT8sa7i4+XVE5Bp2KNHA5A9mqpXlyFBa9e6cf7hw+W8gGzYqf0gPmDjRmDBAml8mjbNvUUM/f2Bzz6TTdp/+w34/nvdilliKCXvK1askDpcu1Ym3xHR1THMGGHVKjl26eLSw00LM4BzIPAnnxi+zbSWAXTtYjpwQMb/5OQAgwc7+zou0VpnXO5q0rzyiiywl5UF3Habz7zCvPCCHAcNAho2dP98DRtKSw8gLTXcubxoVq0CHnhAFs2sW1d6p/v0kZauihVlxtiLLwKHDlldUiLPxDBjBG1lXRen7Ghh5uxZIDNTpzJdSZ8+0nxx5oyM4jTQ+vVy1K1lJj0duPVWqaj27aV16T9NC7qFGZtNupjq1JFB04MHe30/yoYNwMKF0qLy/PP6nXf8eKBaNammN97Q77y+aPNm2Tm+Sxd5ep0+LS1bDRoALVtKPQLA9u3A//2fBJ1HHy3RazoSFYhhRm+nT8uyqECx15fRlC/vXIMlOVmfYl2Rv79z7IyBA4FTUmTBPECnMKMUMHSobMsQEQF89528CvxH585yTEjQYQZ6+fLO6yxcKBsWebFp0+R4992yy4NeSpd2DiiePBk4dky/c/uK7Gxg/vz66NQpAEuXyt/7kCHSvZSaKv9CNm+WoXcnTwJffikTI+12mWTXuDEwZ47X52ki3TDM6G3NGjk2aODcl6CYbDYTFs7La8gQmY68dq0MojDApk1yrFnT5WrJ75NPZB5wQIC0KGlvYf+jaVMgLAw4f16nbZdatpR5zIBM2zFh4LQRjhxxNsSNHav/+e+8E+jYUbqZfHQSmMtSUoCbb/bH1183Qna2DbfdJkH/44+lhea/i0lWqgTcc48MxVu+XJZCOntWvnb//bKzOVFJxzCjN62LyYVZTHmZOm4mIgK4/Xa5PWuWIZfQuph0GS+ze3fuIF+8/PJVxyb5+zsbyNzuatKMGSNvk9PTpbvJxEUH9fLuu9I60LWrvDjqzWaTVhlAGrC4GaU4elRaC+Pj/RAcnI3Zs7PxzTdAjRpFe3zXrvKe48UXZdD2F1/I09+UNz1EHoxhRm/aErcdO7p1GlPDDCCLwgHSdm3ARXWbyZSZKUvVXrggu0k++WShD9G6mnQLM35+MsChbFk5qTZ120tcvOicvDZmjHHX6dIF6NlTQpM20LgkS0qSp+y2bUCVKgqvvroad9+tij2DLDBQxjgtWiTrXq5fL3X977/GlJvIGzDM6Ck727nErTe1zAASvmJjZbbOjBm6n17rvWrTxs0TPfecDCaoWFHelvoV/hTWcqXWaKaLmjWdA0Oee86rVon7/nsZ712jRtF3eXCVNrnsq69K9s7ap08D3btLd1L16sCKFdmoUyfFrXN27y7/bmrVAvbtA669Vo5EJRHDjJ7+/lu6HsLCZISeG0xbOC8vrZXjvfdkkIlOUlOd3QzudGnY/vjDOT3mk0+AqlWL9LhrrpFuj3/+0XmT8KFDJQCmpcn+TV5C227gwQelG85IbdoAAwbIQNWXXjL2Wp4qK0vqYPt2WSxyyRLJwnqoU0emdTdsKIOFu3f3qlxNpBuGGT1pXUyxsUVqMbga01tmAOCmm4D69WXH6I8/1u20W2W/R1SrJs3irghKSYG/tv3C8OGy5ksRhYUBjRrJbbcWz/svPz/prwkIAH74QXbm9nAHDwJLl0q4GzzYnGtOnCjHb791TvQrKZQCRo6UWUplykjXUN26+l6jalU5f7160tXUs6e0BBGVJAwzetJp8C9gUZjx95eVzgDgrbdkHqgOtmyRY4sWLp5AKbScNQu2pCRJJS4sXqJtbKlrmAGAZs2cdTZypLTMeTBtN4bu3Ys+6NRdzZtLTlbKuXVWSfHeezIA2maTyXdNmxpznYgIWQi7alXZ/6xvXy5YSCULw4yedBr8C1gUZgDZiygiQtqs583T5ZTuhhnb7Nmosm4dVGCgvCKUKlXscxgWZgBpeqhZU+ps6lQDLqAPh8MZZrRGLrNc2sgcX30l3X0lwZYtMnsfAF57DbjxRmOvV6MGsHgxUKGCPM+HDOE6NFRyMMzoJSlJ2vBtNucrpxvyhhlT/yGFhOSf9pyd7fYptTDTsqULD96/H/6XXhEckya5nIi0X8m6dfKirqtSpZytRVOneuy0kpUrZTn88uWBW24x99rt2klrUE6OR+c93aSny1o7mZkSYp54wpzrNm4M/O9/0vP59dfOJZGIfB3DjF60xfKaNJFBGm6KjJRjRoYMoDXVyJEyuGXPHmDuXLdOlZPjXKyu2DkkOxu4917Y0tNxqkkTONxY3a1pUyA0VOpy926XT3Nl/fvLhjoZGc7NiTzMN9/IsX9/yaxme+45OX76qe+vCjxqlDzPoqNl8013NvAsruuvd64W8NxzMpyLyNcxzOhFm5KtQ6sMIC+85crJbdMXxAoLc74gv/iiW2Nn9u6VvvtSpWTmRbFMngwkJECFhWHT6NFuTb0JCHBOCzekq8lmA6ZPl0HB33wjzSAeJDtbdmIApMXACl26yF5ZmZnAm29aUwYzLFwogc1mk241XVa8LqaHHwYee0xu33efQQGeyIMwzOhF1yVuhWXjZgBZRK9yZVmu/4svXD6N1sXUrFkxs8j69cCkSQCAnLffxsWICJfLoDF03AwgTU/DhsntUaM8amXg5ctlj59KlWThNivYbM6xMx984JszblJSnFudjRsnrSRWmTZNVgxOS5Op4R4+Np3ILQwzelDKucStjmHGkrVmNGXKAE8/LbcnTXJ5aoRLg3/T0mTjmZwc4M47oe6+26Vr/1fecTOGefFFGZSyZYusheMh5s+X44AB0kpllV69ZOxUerrXLZxcJE8+KVsW1K0rTwUrBQTIGP6oKFnj5pFHOCCYfBfDjB727ZO1WYKDpQlCJ5a2zACynktMjMzScWE6NOBCmFEKePRRGa9TtarMbdVpwIEWZrZuNXDaauXKzrX7n3tO3qpbzG6XVX8B4I47rC2LzebMyDNmSG71FUuWODdS/+QTlybd6S4qSoKsv790eWnbWBD5GoYZHdi0VpmWLWXjFJ1YHmZCQ51L9k+eLKGmmIo9k2n2bODLL2XsyddfyzxTncTESJ1mZzt38TbEo4/KruknTzrX87fQkiWyfUFkpHQ7WO2226Tl4swZ54u/t7twQRaEBuTXf5W9T03XpYtz08/Ro5094kS+hGFGBzZt4yEdu5gADwgzgLyV79xZmjLGjy/WQ0+dkiZ3oIgNVtu3Oze8fOkl2WxGR3lnzRs2bgaQQKuNcH37bRl3ZCFtNkv//sZvX1AU/v7Op9Ibb8iAYG83ZYqszFCtmmcuDPjEEzIdPysLuP12CZJEvsTC3nPfYTNgvAzgIWHGZpMX5LZtpaXknnuAPn2K9FCtVaZOHdlg+qpSUuQt+8WLQFycsy9CZ+3bAz/+aHCYAaSO4uJkFbOnnpLFPyzgcAA//yy3zV5b5mruvRf4v/+TKdpffgk89JDVJXLd/v3OtXPeeqsIz3UL2GzS6Nm6teyTNngw8OOnp+F35JCsi3TqlDQvXbggdy5dWvrJKleWJs1q1WRzVzPnmBMVA8OMm2w5ObBt3iyf+GKYAeQ/4Jgx8p966FBpQSlfvtCHaevLNG9eyB1zcoCBA2XjnqpVnd1MBmjXTo6GhxmbTaaTNG8uA1aWL5d1aEy2caNM7S9b1jO6mDTBwbILxOOPSxB44AHPaDVyxejR0rrUvbsMsPZI2dko9/cafNdjO2I/egALFwbh9YipGI9irGBYoYI8n5s3l37jzp1lQygvDjgnTsjC7bt2Scg7dUqWilJKftxKlaTHuEkTWdrBE4MqCYYZN5U9fBi2ixflWd6gga7n9pgwA8hqwAsXysIxo0YBn39e6D+xHTvkWOh+NE8+Cfz+u4zR+ekn2U7BIG3bSrH//Vf+kRl4KfkP+PDDMoh53DgZrGDyK/aPP8qxVy8JEJ5k2DAZUrR3rzRcWT042RU//wz88ov0LM6c6WGv61lZwG+/ycKXixYBKSloBWAmNmAYPsIzeBUdKuxB17pH5Z9N6dLyN6iUtNCkpQHJyTJW7sQJ4OxZ2dFyxQrnNSIipDu4a1egd2/9d9HUmVLSYjx/PrBgQfE2Pg0IkJbdnj3lvVe9eoYVk1zAMOOm8nv3yo02bXRvTdDCzIkTMmjVyim1KFVKljLt0kVaTjp3dq6pcgVamGnc+Cp3evNNafEBJCC1bq1Pea+gXDmgYUNg507JFn37Gno5mdY+dy6webP8fCZviqRt5H3TTaZetkjKlJGF3SZNkgGqt9/uYWGgEBcvOnf+GDtWnlceYc8emfc+d27+xXzCw4EePfBQx+ZY9dsJfPl7BAYG/4DNPzn/11xRRoasvLd1q3ysWyfNmydOSBLVulHr1pUu1t69JeCEhhr2YxZHZqZUx/TpQGJi/u81bSqzLevUkXrQ8ty5c/JGcudO+ZH//Rf480/5mDhRWnkfekh63j3kxyzZVAmQkpKiAKiUlBRdz5uVlaUO9OypFKDUk0/qem6llMrOVsrPT05/7Jjup3fNlClSoKAgpf7664p3cziUKl9e7rplyxXu9MEHcgdAqVdfveK5srKy1IIFC1RWVpabhReDB8slJ07U5XSFe/NNuWBkpFKpqSZdVKkDB+Sy/v5KnT5dtMfoXdeFOXVKqdKlpZy//mrKJXXzwgtS7qpVlTp/vniP1b2eHQ6lli9Xql8/pWw2599VVJRSjz8uf6vZ2bl3T0tTqkkTuct11yllt7twzYwMpVatkr/dG25QKjDQeV1AqdBQpfr2VWrWLKUOHtTn5yym9PQs9cgjiapKFUdusYKDlbr1VqXmzSv634VS8vf04YdK9erl/L8MKFWxolLPPqvUiePZSiUnK7Vnj1Lr1yv1xx9K/fCDUt99p9Q33yg1f75c9KeflFq2TKkNG5TavVups2fl9+fFjPy/UdTXb4YZN2RlZamztWvLM/qbb3Q9t6ZKFTn9pk2GnL74HA6l+veXQlWooNTWrQXe7dgxuYufn1IXLxZwh7ffdv7THT/+qn/Mev+hzJoll+3VS5fTFS4zU6m6deWizzxj0kWVmj7d+WJVVGaHGaWUGjdOynnttaZd0m0HDigVEiLlnjev+I/XtZ5XrpTKyxsk+vVT6rffrppSdu5UqkwZHZ+Wqany4j10qFLVquUvD6BUo0ZKPfGEUkuXyt+EwRYsUKpePWeIqVpVqcmTixdgLnPmjFKrV6uk179Qb3T9SdUsnZx7/tI4r57FS+oMyl/+sxf2ERoq/yO6dFHq3nuVeukleU1JTFQqPV23OjEKw0wxvPPOO6pGjRoqODhYtWvXTq1du7bIjzUszKSmqhx/f3kyGvTOo1UrD3zXmpamVGysFCwiQql16y67yx9/yLfr1//PN7KynK9egFKjRxf6rkTvP5R16+TS4eEmviFasMD5ttCkd6nXXy+XnDat6I+xIswcOeJ8U796tWmXdctNN0l5b7jBteeQLvW8caMk8rxNDo88otSuXUU+xddfOx++cKHrRbmMwyFvdKZMkRdo7f+k9lG2rLwp+vhjpY4e1fHCSh0+rNQttzgvVa5chpo+Pbt4+enUKQmJ772n1GOPKdWtm7Ry/SeE2OGvvkN/1Rbrcr9cHmfU5LBX1cVGreT/ZOfOUgddu8rxmmuUathQAl9YWNHCTr16St1xh9Tn4sVKnTypa525i2GmiObNm6eCgoLUp59+qrZv366GDh2qypcvr5KTk4v0eKPCjH31aqUA5ahUybBXxd695bn86aeGnN51Z886k1ZoqFKffJKvDmbMkG/dckuex+za5QxBgLxNKkK96f2HkpEhvWSAUvv26XLKwjkc8soHyD8lg50753z9KM7PaEWYUUqphx6Ssvbta+plXfLrr1LWgACltm937Rxu1fOZMxJatJbNgAClHn5YXsVd8OijzobWf/5x6RSFO3tWWhoGD5Y3QAW12jz0kPyj273bpf+nDodS774rOUmrlqeeylZz5y4suJ4dDqWOH5eWolmzlBoxQt4BFFS+vB/Vq0uIHDtWmj+/+045EtaoHz4+pZo2cbYE1aql1PffF+FHuXBB/khXrpR0+eqrUk8dOsgv5UrliImR/rJXXpGA41aTk3sYZoqoXbt2asSIEbmf5+TkqOjoaDV58uQiPd6oMJN9qR0/x8D+igceKHRIiXVSU51pS+vPWLRIKbtdPfLIpebrCZfeoQ0fLv9d5K2SUt9+W+TLGPGH0q6dFGXuXN1OWbjEROcLkMFNEFpDUL16xXucVWFmzx7nOITERFMvXSyZmdLaCEgDo6tcqmeHQ6kvvsj/YnvXXW4n8owMpdq2ldO1a2dCD1BOjowpmTRJLph3jI/2UaGCdJ0NH67UO+8oFR8v/WJXGJx06pT0rGkP79BBqb//ViorPV0t+ugjZV+6VKkvv1Tq5ZeVGjJEqY4drx4UAKVq1FCqTx/pGvv0U6XWri10zFt2tvyKoqOdp+nWTcriEodDxuEsWiStMnfc4eyyLuijTh2l7rxTqddflzFUJo3Ry8zMUu++G29pmPH42UxZWVnYuHEjJkyYkPs1Pz8/dO/eHQkJCQU+JjMzE5l5lhVNTU0FANjtdtjtdt3KZru0WElOq1bI0fG8eVWu7AfAH8eO5cBudxhyDZeFhADffw+/6dPhN2kSbMuXA8uXQ5Uvj+05SwG0QqP3RgKT3819iKNPH+S89RZQq5ZsGlQE2u9Mz99d27Z+WLfOH2vW5OC220yq18aN4f/gg/D75BM4Ro9Gzp9/GraezqJF8rzp1q14zxsj6vqKTp2Cbc0a2HbsQO1Dh3BblXvwzdFrMbn3Csy94SOoypWBevWgmjaFat5cpg5b7M03/bBnjz8iIxWeeSa7qE/hyxS7nnfuhP+oUfC7NC1aNWyInHfegdL2TXDj9+XnJzN92rcPwLp1NowZk4O33zb4b6JFC/mYMEGeBwkJzo8NG2A7exZYtUo+/kOVKyeLwJQuDVW2LP7MbIu7tz+PI1kRCLJl4bUqb2HkkffgH3satrQ0xF2lGMpmA2rXhmrQAKphQ6jGjYHGjaEaNpTpdgUppK4HDgRuvBGYOtUPb73lhyVLbGjRQuGRRxyYONGB8PBi1BMgP+v11+ffgj01FbbERNg2bnR+7N8vKzju35+7s6yy2YD69aHatoVq00Y+WrTQbeOw7Gzghx9smDbND1u2XI+4uExUr67LqXMV9W/EppRS+l5aX8eOHUPVqlXx119/ITY2NvfrTz31FFasWIG1Bax+9sILL2DSpEmXfX3u3LkopePubzeMHImyR45gzbPPIlnnBfM0CxfWxscfN0OnTkfx5JMbDLmGHkKTk1H3p59QbcUKBKaloRJO4QwqYhNaoUXANiS3aYMDN96IUzpuxOmOZcuq4e2326Bhw9OYMmW1adcNPncO3YYPR+DFi9g0ejQO5/0HpaNHH+2GY8fK4Omn16FDh+OGXMMVZQ8dQvSffyI6IQFhhw7l+14iWqAVEuGHHOxGA9SFcxsIh78/zjRogJMtWuB4bCzO6/0fswjOnAnBo492Q0ZGAEaN2oQbbij+XmXF5Z+ZifrffIO6P/4Iv+xsZAcFYc+dd2LfTTdB6bgPHACsXx+JV17pAAAYNmwL+vT5R9fzF5Wf3Y4yR44g7NAhlD10CGH//otSJ04g9NQpBF64kHs/B2x4DePxPF5CDgJQD3vwDe5AS2zJdz5HQAAuVKqEi5Ur42LlyrhQuTLSqlXD+WrVkBYdDYeBCzAlJ5fCZ581wZo10QCAsmUzMWjQLvTo8Y/uS04Fnj+P8gcOoPzevSi/bx/K79+PUidPXnY/h58fzlevjnN16uBcvXo4V7cuUmvUgKMYz6eMDH8sWVIdP/1UB8nJ8iYjKCgH48Zt1P3/zYULF3D33XcjJSUFYWFhV7yfT4aZglpmYmJicOrUqatWRnHlrF6NvXPnos7EiQgsdKEG13z7rQ2DBgXg2msdWLIkx5Br6ConByeW70C13q1hsymk/L4aIR1auLUQg91uR3x8PHr06IFAnf6B794NNGsWiJAQhdOns/XcH7RQfm+8Af9nnoGKjkb29u26tzgcOgTUrRsIPz+FpKTsoizWnMuIukZODmw//wy/GTPgtzp/cFQNG0K1agVVsyZQpQpu/PBm/L6tOoZesxnvdfwctl27YPv7b9iOHcv/uObN4bj7bjjuu0+WaTXB/ff7Y+5cP7Rv78CKFTluNaoVpZ5tv/4K/zFjYPvnHwCXWjWnTwdq1nT9woWYMsUPEyf6w89P4ccfc9Czp4e9PKSmAkeP4sS/GXjghdqI3yS/+7s6HcSshzahbBkl/2vCw6EqVIC9TBnEr1+PHj176vd8dsGyZTaMHeuPHTtkIaUWLRTeeisHnTsbXL/JybBt2iQtNxs2yDE5+bK7qaAgoEEDqFq1oGrXBmrVkttVq8qWFpUqAQEBSE4G3n3XDx984IczZ+RnqVhRYdiwbDRo8Aduv72r7vWcmpqKSpUqFRpmPH7MTGZmpvL391c//PBDvq/fd9996qabbirSOYycmm30+IIVK1wb+2ClZcuc3bd6MKKec3Jk6A6g1ObNup22aDIyZHQgYMhiNx9/7Bw3UFy61rXDIVNktAVNtFGZ/frJ+IVTpy57yMqVcregoP9Mctm/X9Yl6tfPOfYKkPnRDz5o+C/x0lh/ZbPJcA93XbWeDx2SgZ15B3r+8IMpU+8cDqXuv9854egKKy9Y6o8/nBOLQkNlOMuVqsaqMWAFsduVmjnTuf4WoNTAgfLrNo3DIdMHf/hBFsfp2VOmdRYym2oX6quhwbNVsC3DOTwn9Kia1fx9ld7/HpVz++3q8LXXqixXR8Rfhc8NAB45cmTu5zk5Oapq1aqWDwA24w9l927nPxZvoa3j0q+fPuczqp67d5dyfvCBrqctmu++c74Y//uvrqceOFBO/fzzxX+sbnW9c6dzbrg2oPOZZ4o0DbdTJ3nI449f4Q6nTin1/vtKtW6d/59ujx6ShnSWna1Uy5ZyiYce0uecBdZzVpYM3NRWEQwIkMU4i7sin5syM2UsPyCzhy1a7+4ydrs8p7Xxwk2aFD6bzJPCjObkSZl8pv0cpUrJuOQC1+Myg8MhCyf9+qsMth43TqahNm+uVpfvq27GD8qGnNw/s/ZIUN+hv8qG32Whx75qle7F86kwM2/ePBUcHKxmz56tduzYoYYNG6bKly+vkpKSivR4bw4zqanO50pammGX0ZU21XP8eH3OZ1Q9P/OMlHPIEF1PWzQOh6w5ASh19926nTYnR6lKleS0rryuu13XWVky9S44WAoRHKzUU0/J1NwiWrhQHlq6dCGzTR0Opf78U2Zv5F3HpEsXmf2iU0vGe+/JacuXV+rECV1OeXk9r1ihVNOmzp+hc2c3psC47/RpmS2tTTE+csSyoiilZNa59ueihcqirCXniWFGs2mT/Jq1n6lmTVnhwuqiZmfLlPK8q2gASvW7LkWtfHuTcvy8UGajfvGFvBOcMUNlT5umtg4ZorIMaGbyqTCjlFIzZ85U1atXV0FBQapdu3ZqzZo1RX6sN4cZpZzrJuzebehldKO9q/v8c33OZ1Q9a9OXmzXT9bRFt3Gj8+1ZQoIup9y0SU5Xpoxr/xTdquu9e5Vq08b5369XL5fe1jscSjVvXsxAfPCgvN3Nu6R+hw5K/fKLW6EmKcnZLfD22y6f5jK59XzokFL33OMsc8WK0m+Sk6PfxVx05IhS2gLnDRpIXVjhxx+dPSFlyig1Z07RH+vJYUYpeWrOnSurE2tPgdq15SlgdpFPnVLqjTfyz/wOCpLguHPn1R/LdWZM4u1hpmFDeWItXWroZXSjLYOxYYM+5zOqnvNuuWByS76TtpBQq1YubpCT32uvyeluvNG1x7tc199840zdFSpIknUjRPz0k7MXrlhv9g4flhVbtb0GAAlYP/zgUkC4+245RevWuvx6cmWlpamtDz6oHNoKsDabLIRn4cJnBTl4UIbsaOP2Dhww79oXL8qvMu+vcc+e4p3D08OMJj1dgkTeJYSqVpVdDYwMkTk5shzNvfc6G1O1VshnnpE1BYuCYcYk3h5munWTJ9gXXxh6GV2cPKl/t5iR9ay9I1qxQvdTF01SknPxrilT3D6dNg5o+nTXHl/sus7MlJVT83aPuLgSbV55e+Huv9+FExw/LoudlSrlLFuzZrLZX54NF6/m99+dYVevYK5ycpSaO1c5tAHggCxvr8eoYoPs2SPrxwGyV9wVN47V0aZNSrVo4ayiceNcW8zPW8KMJi1NQk1kpPNnDwyUnR/mzdPnTVdWluwPOmZM/sX9tND+0UcesHFqHgwzeXh7mLnvPnmiFXG8s6W02Sg1a+p3TiPrWZs08vrrup+66D7/3Dm+xI2+xAsXnO+uTFlm/+TJ/BscTpiga/PF2rXORguXX0BPnJByaa1GgDR1fvnlVcuanu6ccDZ6tIvXzisnR6mff87XDXexQgVlf++9IocrKx09KllQG8vkyuaaRZGRIZNstCFQlSpJT6GrvC3MaDIylPrqq8vHrYSGyjj3l1+WWaPJyYU3gJ46pdSSJRKSbrop/5+C1gozZEiBW+wVGcOMSbw9zEyYIE+6PBO6PJY2WLJPH/3OaWQ9T54s5b39dt1PXXQOh1JxcVKQa691ebzE4sVyiuho13t4ilzXO3Y4B1SEhbn3inMVd9whl4iLc3M875kzSr3wQv55sTEx0o5fQFv6U085Z/O4tSJ8ZqY0qeYd3FumjMp+4QX187x5XvUie/asc3sx7f+RXq2vDoc8hbQude1v0t0uFm8NM3lt2SJdPnXqXDZ5KLdXt0kT+dfRq5e0znbpInV5pX0sw8OVGjRI8rUe21cwzJjE28PMO+/IE/DWWw29jC60Pu4nntDvnEbW85IlUt4aNXQ/dfEcPOickjtzpkunePJJefjgwa4Xo0h1vWiRc5GeWrVcbwYqgn37nJuCfvedDidMSZGN+bQpX4BMgR4wQGZopKer1aud+0T9+KML19B2jB47Nv91ypaVX1Jyste+yNrtzjdXWgusm2Os1dq1ziwPSBeLLr9r5RthRuNwKLVtm7we3Hab/OkVtK1VQR+1a8tTfMoU6TLVe3y5J4QZj9+biYCqVeV49Ki15SiKHTvk2KSJteUoqjZtAJsN+PdfIDkZiIy0qCA1awJTpgCPPQY8+SRw3XVA06bFOsUff8ixRw/dS+f07rvAqFFATg7QuTPw/feyQqhB6tQBnn4aePFFuWxcHFC2rBsnDAsDnnkGGDcO+PZb4L33gIQE4H//A/73P6SFVsZ9flvhcERhcL8zuKlvOQBFWHf+5Elg7VpgyRLg559lfxxNlSpS+EceQe5yzGbsfWWAgADg1VeBLl2Ahx8G/vkH6NsX6NRJqrVnTxRpmf6MDODXX4GZM4Hly+VrQUHA6NHAs88C5coZ+VN4J5tN/q82aQKMGCFfu3gR2LcPOHECOHMGSE+X31FgoCzaW7WqfLj1N+MlGGa8gDeGmcaNrS1HUZUrBzRsCOzcCaxfLxvEWWbECPkP/9tvwF13AevWFXkbiJMngc2b5Xb37gaULTtbAsDMmfL5ffcBH34IGLivjWbCBGDOHMkHEycCb72lw0lDQoB775WPLVvkAt9+iyf+GY8DiEJ1/Iu3f24OlM4E6tUD6tYFKlaUTf8AIDMTSEmRFHzwoOwhkVdQENCnDzBkCNCrl7zC+JBevYDt24EXXgDeeQf4808JNVWqALfcImGncWMgOlrCzYULEnz+/htYsUKe4ikpcq7AQGDQIOC55yS8UtGFhgIest2d5XzrL8xHaWEmKUneEOu9QZlezp4Fjl/aY6xRI2vLUhzt2kmYWbfO4jBjswGzZwPNmwPbtkkLzTvvFOmhS5bIsXlzA1qXUlJkK+Dff5fPJ08Gxo+X8pogJASYNUteQGfMAAYMkEYh3Vzawfnbtq/hgzvlZ5rddhbK7XIAaZnyu9i2rfDzNGwIdOwor+o9evj82+EyZYA33pCM+8YbwOefy9//e+/JR2GqVZMQM3Kk3CZyB8OMF4iMlACTkyNdIdHRVpeoYFqrTEyMd/0fb9dO/hGvX291SQBERABffCHt9bNmAe3bS+tBIeLj5ah7F9M//0jC275d3gZ+9RXQv7/OFylcz57A4MHye7r3XiAxUd+uiF27gAeHSJAZPx64fspUIGeytLjs2gUcOACcOyeJ3WaTFqkyZYDq1YEaNaRLsIT2jURHA9OmSS/p778DS5cCf/0lDVanTsl9/Pzk/0K9ehJEu3WT3OfOZp1EeTHMeAF/f2m+PXJEupo8Pcx4SxeTpl07Oa5bJ8PlTGpwuLK4OGlzf/llYOhQoEEDZyELoJQzzOjaxZSQANx8s/RhVakiY0HatNHxAsUzYwawcqW8SI4YAXz5pT6/q5QUae1JS5OhSi+/fOkb/v5ArVryQYUKCgJuukk+NHa7/I78/BhcyFh8enkJravpyBFry3E13jb4V9O8ufwjPnNG3oB7hEmT5FUhMxO49dar/uL37AEOH5afoUsXfS5vmzcPuP56CTItW0rSszDIADJ296uv5EVxzhxg+nT3z5mVJUFmxw7Ja/Pm+dzwFksFBkp9MsiQ0fgU8xLeMAjYW1tmgoLk9RqQ12yP4OcnTQ+NGwPHjkn/0cmTBd5Va5Xp1AkoVcrN62Zno/Hs2Qi47z4JUjfdBKxa5TGDGjp2lPEZAPDEE8Avv7h+rpwc4IEHZLxRmTLAwoUWzmYjIrcwzHgJhhlj5e1q8hhhYTLtIyZGxm3ExcmYjf/QbbxMUhL8e/ZEvQUL5PMnn5Sp12XKuHlifY0ZI5OEHA7gttucP39x2O0y+HTuXGk5+N//gNatdS8qEZmEYcZLeHqYSUlx9oR400wmjUeGGUAGmP7xhwwMTkwErr02X5dTdjawbJncdivMLFoEtG4Nv1WrkB0SguyvvwamTvXIqXM2myx306+frFdy002yZExRnTols6bnz5dukPnzJScSkfdimPESnh5mdu6UY3S0c10wb6KFmU2bPHA9s/r1pS8kOlpmFXXsCGzcCEDC1/nzQHg40KqVC+dOS5PF3Hr1Ao4fh2rUCCvefBNqwAB9fwadBQUB330nQSYjA7jjDmDsWPlxruaXX6QF5o8/pEvuxx8tmZxFRDpjmPESnh5mvHXwr6ZePZlZm5FRtCVFTNe0qcx3bdBARvt27AjMmIH4xQ4AMtW1WI0oSkkfS6NGwAcfyNdGjUJ2QgLStCebhwsKku6hJ5+Uz6dPl+p57TUZyK2UfD0lRYLPDTfILPPDh+X3vXYt0Lu3ZcUnIh0xzHgJbwkz3jheBpDxttdcI7c9rqtJU6OGTJe+5RaZhjN6NOLf3AqgGF1MDgewYAHQoYMMGjlyRLZSWLIEePttHUYQmysgQHrDfvlFZlAfOybbH9SpI2sdVawoLYW33y7dcf7+MnB406Zi7xZBRB6MYcZLaGEmLQ1ITbW2LAXx9jADePC4mbwqVJBBue+8g9Qy0ViTJq/I3d+/DfjoI3k1/6+sLGmGeO45aZK49Vb5IUuXlkVVduyQZgsv1qeP/BiffiqLsgUGyj41Z87I9+vVA556SlpsXn/d48Y0E5GbuKKClyhdWrpBtIG2nhYatm+Xo6eVqzi8IswAMgJ2xAgsL3M3cu4PQB3sR61N/wOG/U++X6mSTKXWFs85dEgCjaZ8eeDRR2XzQx+aixwSIlOtH3hANuA7dky6DatUkTFFROS7GGa8SLVqEmaOHvWs0HD+vHOfPU8qV3FpYWbHDmkB8/R37/EbZNPDHvdFAQ1eke6jDRtkuo62jrymYkVZUe+OO2QaUOnS5hfYRKGh3LSQqCRhmPEiVatKC4injZvZtUuOUVHe/Q64ShUJjEeOyJgKvVbTNUru+jI3lwb6PwM884xsT7xzp4SZzEzplqpWTcbFWL5PAxGRMRhmvIinDgL2hfEymnbtJMysW+fZYebwYWD3bhm4nG+4S6lSlm87QERkNg4A9iIMM8bz+BlNl/zxhxyvucY71/UhItITw4wX8dTNJn1h8K/GWwYB67aFARGRD2CY8SLVq8vx8GFry/FfvtQy06aNDC35918gOdnq0hTM4XC2zDDMEBExzHgVLcxoM4c8QXo68M8/cttbV//Nq1w5oGFDub1+vbVluZKtW2UD7dKlZe07IqKSjmHGi2hh5syZwvegMcvu3bJsfOXKsryJL/D0riati6lrV1lKhoiopGOY8SJhYdJyAHhOV5MvdTFpvCXMsIuJiEgwzHgZT+tq8qXBv5q8YUbbrNBTZGQAq1bJbYYZIiLBMONlPC3M+GLLTPPm0n1z9iywf7/Vpclv9WrnEv2+VOdERO5gmPEynhpmfGHwryYoCGjVSm57WleT1sUUF8cFfYmINAwzXsaTwszFi7ILMeB7rQSeOm5m8WI5xsVZWw4iIk/CMONlPCnM7Nkja56EhwMREVaXRl9amPGk6dnJyUBiotzu3t3SohAReRSGGS/jSWFGG/zbqJHvdXlo2xps2gTY7daWRaMtlNeqle+FRyIidzDMeJm8qwA7HNaWxRfHy2jq1ZMNpzMygM2brS6NYBcTEVHBGGa8THS07JRst1u/3L7WMuOLYcbPD7j2Wrm9cqW1ZQFkijjDDBFRwRhmvExAgHPDSau7mnw5zABAly5y9IQws20bkJQEhIYCnTpZXRoiIs/CMOOFPGHcTEaGcw0WX5vJpNHCzKpV1nfpaa0y110HBAdbWhQiIo/DMOOFPCHM7N4tL/AVKgBRUdaVw0itWslmjufOScuIldjFRER0ZQwzXqhGDTlaGWbydjH52kwmTUCAs0vHyq6mixed12eYISK6HMOMF/KElhlf3MagIJ4wbkbbwqBqVZkGT0RE+THMeCFPCDO+PvhXkzfMWLXp5G+/yZFbGBARFYxhxgtpYebff60rQ0kJM9dcIwNuk5OBvXutKcPChXLs29ea6xMReTqGGS+kjZk5fRo4f97865eEmUyakBCgfXu5bUVX0549EqICA4EePcy/PhGRN2CY8UJhYUDFinL74EHzr18SZjLlpXU1LVtm/rV/+cVZhrAw869PROQNGGa8VO3actR2rTZTSZjJlJe2qeMff5i/3owWZtjFRER0ZZaGmZo1a8Jms+X7mDJlSr77bN26Fddeey1CQkIQExODqVOnWlRaz2JlmCkpM5k0sbGy3syJE8Dff5t33dRUYMUKuX3jjeZdl4jI21jeMvPiiy/i+PHjuR+PPfZY7vdSU1MRFxeHGjVqYOPGjXj99dfxwgsv4MMPP7SwxJ6hVi05WtHNVFIG/2qCgoCuXeV2fLx5142PB7KzZdPLevXMuy4RkbexPMyULVsWUVFRuR+lS5fO/d6cOXOQlZWFTz/9FE2aNMHAgQMxatQoTJs2zcISewZPaJkpKWEGcA6+NTPMaF1MbJUhIro6y8PMlClTULFiRbRq1Qqvv/46srOzc7+XkJCALl26ICgoKPdrPXv2xO7du3H27FkriusxrGqZycgA9u2T2yWlmwlwhpmVK6UOjJaTw/EyRERFFWDlxUeNGoXWrVsjPDwcf/31FyZMmIDjx4/ntrwkJSWhlvaqfUlkZGTu9ypUqFDgeTMzM5GZmZn7eWpqKgDAbrfDbrfrVn7tXHqes6hiYgAgEAcPKmRlZZs2EHfbNsDhCESFCgoVK2bDjB/dynrW1KsHREcH4NgxG1asyMYNNxi7gt7KlTacOBGAChUUYmPNqWfAM+q6JGA9m4P1bA4j67mo59Q9zDz99NN47bXXrnqfnTt3omHDhhg3blzu15o3b46goCA8/PDDmDx5MoLd2Bp48uTJmDRp0mVfX7x4MUqVKuXyea8k3sy+h0uys23w8+uHjAwb5sxZgvDwzMIfpIOVK6sCaIuoqDP47bfVplxTY0U959WgQSscO1YdH354EBkZOwy91scfNwVQBy1bHkZ8/GZDr1UQq+u6pGA9m4P1bA4j6vnChQtFup/uYebxxx/H/ffff9X71NYGfPxH+/btkZ2djX/++QcNGjRAVFQUkpOT891H+zzqKgucTJgwIV9QSk1NRUxMDOLi4hCm42Iddrsd8fHx6NGjBwIDA3U7b1FVrw788w9Qu3Z3dOxozlr7a9ZIz2SnTuXRp08fU65pdT1rUlJsWLYM2LOnLvr0qWnYdRwOYORI+dN87LFo9OlTxbBr/Zen1LWvYz2bg/VsDiPrWetZKYzuYaZy5cqoXLmyS49NTEyEn58fIiIiAACxsbF49tlnYbfbcysoPj4eDRo0uGIXEwAEBwcX2LITGBhoyBPaqPMWpnZtCTOHDgXkzrYxmjb4t1kzfwQG+ptz0UusqmfNjTcC/v7Atm02HDkSiP/0gOpm7VrgyBGgTBmgd+8AWPEjW13XJQXr2RysZ3MYUc9FPZ9lA4ATEhIwffp0bNmyBQcOHMCcOXMwduxY3HPPPblB5e6770ZQUBCGDBmC7du3Y/78+Xj77bfztbqUZFYMAt66VY4tWph3TU8RHu5cDfinn4y7zv/+J8e+fWU7BSIiujrLwkxwcDDmzZuHrl27okmTJnjllVcwduzYfGvIlCtXDosXL8bBgwfRpk0bPP7445g4cSKGDRtmVbE9itnTs1NSpCUIAJo1M+eanuamm+RoVJhRyhlmBgww5hpERL7GstlMrVu3xpo1awq9X/PmzbFq1SoTSuR9zG6Z2bZNjtWqSStFSdSvHzB2rKzMe/as7E+lp3XrJJyGhgK9e+t7biIiX2X5OjPkOq1lRtvB2mhaF1Pz5uZczxPVqSOLBebkAL/9pv/5v/xSjrfeKmNmiIiocAwzXqxuXTkePQoUcfaaWxhmxM03y/G77/Q9r90OzJsnt++9V99zExH5MoYZL1axorO7Z+9e46/HMCMGDpTjL78A587pd97ffwdOnwYiI507dRMRUeEYZrxcgwZy3LPH2Os4HM4do0vq4F9Ns2ZA06ZAVhbw/ff6nVfrYrrrLiDA0rW5iYi8C8OMl6tfX45Gh5l//wXOnwcCA50BqiS7+245zp2rz/lOnAB+/FFus4uJiKh4GGa8nFlhRutiatwYlizi5mm0rqalS4Fjx9w/36efSkvPNdcArVu7fz4iopKEYcbLmR1mSvp4GU2tWkCnTrIuzOzZ7p0rJwf44AO5PXy420UjIipxGGa8nFlhRhsvwzDjpK3d+MEHEkhctWiRLEZYvjxw5516lIyIqGRhmPFy2vTsM2dkJoxR2DJzuTvukNlkhw4Bv/7q+nlef12ODzwAGLCpOxGRz2OY8XKlSsnu2QCwe7cx10hPd7b8MMw4hYQAQ4bI7ZkzXTtHQgKwfLmMQxo7VreiERGVKAwzPsDorqbERBkbUqUKEBVlzDW81fDhspN2fDywfn3xH//qq3K8914gJkbfshERlRQMMz7A6DCzcaMc27Qx5vzerFYt4J575PaLLxbvsatXAwsXAn5+wPjx+peNiKikYJjxAVqYMaqbadMmOXLKcMGefVYCycKF0m1UFA4H8Pjjcvuhh5y/QyIiKj6GGR/QqJEcd+ww5vxsmbm6evVk8C4APPpo0WY2ffKJ7JBdpkzxW3SIiCg/hhkf0LSpHPfuBTIy9D33hQvOkMSWmSubPBmoUEHGF02bdvX7HjwIjBsntydNkr2YiIjIdQwzPqBKFXkhzcnRv6tp61bpEomIAKpW1ffcvqRyZWDqVLn9zDPAqlUF3y81VXbdTksDrr0WGD3avDISEfkqhhkfYLM5W2e2bdP33HnHy9hs+p7b1wwZItscZGcD/foBf/6Z//unTwN9+sgChJGRwFdfyUwoIiJyD/fm9RFNmkhrgN5hhuNlis5mAz76CDh6VH4XXbsCDz8sxwMHgOnTgeRkoFw54OefnesDERGRexhmfITWMrN9u77n5Uym4ilTBvjtN2mlmT8fePdd+dA0bAh8952ETyIi0gfDjI8wopvp4kXn+dgyU3SlSwPz5gFDhwJffAHs2wdUqiRdT/feCwQHW11CIiLfwjDjI7R3+gcPyuDSMmXcP+fGjTL+IyqKXSKu6NZNPoiIyFgcAOwjKlVybjWg13oz2gJwHTpw8C8REXkuhhkfonU1JSbqc741a+QYG6vP+YiIiIzAMONDtEG62gwkdyjlbJlhmCEiIk/GMOND2raVox5h5vBh4PhxICCAg3+JiMizMcz4EC10/P03kJXl3rm0VpkWLYBSpdw7FxERkZEYZnxIrVqyrUFWlvtTtDlehoiIvAXDjA+x2ZytM+52Na1cKUeGGSIi8nQMMz5GCzMbNrh+jnPngM2b5fZ117lbIiIiImMxzPgYPcLMqlUym6l+fSA6Wp9yERERGYVhxsd06CDHxETg/HnXzrFsmRzZKkNERN6AYcbHxMQANWoADodzEG9xLV8ux+uv161YREREhmGY8UHXXivHVauK/9izZ50rCHftqluRiIiIDMMw44PcCTN//CHjZRo2BKpU0bdcRERERmCY8UFamFmzpviL5/3yixz79NG3TEREREZhmPFBDRvKLtoZGcDatUV/nMMB/Pab3O7b15iyERER6Y1hxgfZbEBcnNzWwklRbNwInDgBlC0LdO5sTNmIiIj0xjDjo3r3luOvvxb9MT//LMe4OCAoSP8yERERGYFhxkf17CktNFu2AEePFn5/pYD58+X2zTcbWzYiIiI9Mcz4qMqVgWuukdvaoN6rSUwE9uwBQkKAW24xsmRERET6YpjxYVoomTev8Pt+/bUcb7xRxswQERF5C4YZH3b33XJcvhw4cuTK98vKAr74Qm7fdZfhxSIiItIVw4wPq1FD1pxRCvjqqyvf7/vvgeRkWSSvXz/zykdERKQHhhkfd//9cpw1C7DbL/++UsD06XL7kUeAwECzSkZERKQPhhkfd/fdQGSkdDNp42Ly+uUXWVgvNBQYNsz88hEREbmLYcbHhYQAY8bI7eeeA9LSnN+7eBF44gm5PWoUEBVlevGIiIjcZliYeeWVV9CxY0eUKlUK5cuXL/A+hw4dQt++fVGqVClERETgySefRHZ2dr77LF++HK1bt0ZwcDDq1q2L2bNnG1VknzV6NFCrFnD4MDB8uGxboBTw6KPA7t0yVmb8eKtLSURE5BrDwkxWVhZuv/12DB8+vMDv5+TkoG/fvsjKysJff/2Fzz//HLNnz8bEiRNz73Pw4EH07dsX119/PRITEzFmzBg89NBDWLRokVHF9kmhocDHHwP+/jIQuHNn+Zg9G/DzAz77DKhQwepSEhERuSbAqBNPmjQJAK7YkrJ48WLs2LEDf/zxByIjI9GyZUu89NJLGD9+PF544QUEBQXh/fffR61atfDmm28CABo1aoTVq1fjrbfeQs+ePY0quk+64QaZfj1kCJCQIF8LCZGQw6okIiJvZliYKUxCQgKaNWuGyMjI3K/17NkTw4cPx/bt29GqVSskJCSge/fu+R7Xs2dPjNEGgVxBZmYmMjMzcz9PTU0FANjtdtgLmtLjIu1cep7TSLffLqsCL1ggDXK33upAjRoFz3LyJN5Wz96MdW0O1rM5WM/mMLKei3pOy8JMUlJSviADIPfzpKSkq94nNTUVFy9eRGhoaIHnnjx5cm7LUF6LFy9GqVKl9Ch+PvHx8bqf00j168tx+3b58BbeVs/ejHVtDtazOVjP5jCini9cuFCk+xUrzDz99NN47bXXrnqfnTt3omHDhsU5re4mTJiAcePG5X6empqKmJgYxMXFISwsTLfr2O12xMfHo0ePHgjkAi2GYT2bh3VtDtazOVjP5jCynrWelcIUK8w8/vjjuF9bhe0KateuXaRzRUVFYd26dfm+lpycnPs97ah9Le99wsLCrtgqAwDBwcEIDg6+7OuBgYGGPKGNOi/lx3o2D+vaHKxnc7CezWFEPRf1fMUKM5UrV0blypVdKtB/xcbG4pVXXsGJEycQEREBQJqowsLC0Lhx49z7/Prrr/keFx8fj9jYWF3KQERERN7PsKnZhw4dQmJiIg4dOoScnBwkJiYiMTERaZdWbYuLi0Pjxo1x7733YsuWLVi0aBGee+45jBgxIrdV5ZFHHsGBAwfw1FNPYdeuXXj33XfxzTffYOzYsUYVm4iIiLyMYQOAJ06ciM8//zz381atWgEAli1bhuuuuw7+/v5YuHAhhg8fjtjYWJQuXRqDBw/Giy++mPuYWrVq4ZdffsHYsWPx9ttvo1q1avj44485LZuIiIhyGRZmZs+eXehqvTVq1LisG+m/rrvuOmzevFnHkhEREZEv4d5MRERE5NUYZoiIiMirMcwQERGRV2OYISIiIq/GMENERERejWGGiIiIvBrDDBEREXk1y3bNNpNSCkDRN6wqKrvdjgsXLiA1NZX7fhiI9Wwe1rU5WM/mYD2bw8h61l63tdfxKykRYeb8+fMAgJiYGItLQkRERMV1/vx5lCtX7orft6nC4o4PcDgcOHbsGMqWLQubzabbeVNTUxETE4PDhw8jLCxMt/NSfqxn87CuzcF6Ngfr2RxG1rNSCufPn0d0dDT8/K48MqZEtMz4+fmhWrVqhp0/LCyMfygmYD2bh3VtDtazOVjP5jCqnq/WIqPhAGAiIiLyagwzRERE5NUYZtwQHByM//u//0NwcLDVRfFprGfzsK7NwXo2B+vZHJ5QzyViADARERH5LrbMEBERkVdjmCEiIiKvxjBDREREXo1hhoiIiLwaw4wbZs2ahZo1ayIkJATt27fHunXrrC6ST5k8eTKuueYalC1bFhEREbjllluwe/duq4vl86ZMmQKbzYYxY8ZYXRSfc/ToUdxzzz2oWLEiQkND0axZM2zYsMHqYvmcnJwcPP/886hVqxZCQ0NRp04dvPTSS4Xu70NXt3LlSvTr1w/R0dGw2WxYsGBBvu8rpTBx4kRUqVIFoaGh6N69O/bu3WtK2RhmXDR//nyMGzcO//d//4dNmzahRYsW6NmzJ06cOGF10XzGihUrMGLECKxZswbx8fGw2+2Ii4tDenq61UXzWevXr8cHH3yA5s2bW10Un3P27Fl06tQJgYGB+O2337Bjxw68+eabqFChgtVF8zmvvfYa3nvvPbzzzjvYuXMnXnvtNUydOhUzZ860umheLT09HS1atMCsWbMK/P7UqVMxY8YMvP/++1i7di1Kly6Nnj17IiMjw/jCKXJJu3bt1IgRI3I/z8nJUdHR0Wry5MkWlsq3nThxQgFQK1assLooPun8+fOqXr16Kj4+XnXt2lWNHj3a6iL5lPHjx6vOnTtbXYwSoW/fvurBBx/M97X+/furQYMGWVQi3wNA/fDDD7mfOxwOFRUVpV5//fXcr507d04FBwerr7/+2vDysGXGBVlZWdi4cSO6d++e+zU/Pz90794dCQkJFpbMt6WkpAAAwsPDLS6JbxoxYgT69u2b73lN+vnpp5/Qtm1b3H777YiIiECrVq3w0UcfWV0sn9SxY0csWbIEe/bsAQBs2bIFq1evRu/evS0ume86ePAgkpKS8v3/KFeuHNq3b2/K62KJ2GhSb6dOnUJOTg4iIyPzfT0yMhK7du2yqFS+zeFwYMyYMejUqROaNm1qdXF8zrx587Bp0yasX7/e6qL4rAMHDuC9997DuHHj8Mwzz2D9+vUYNWoUgoKCMHjwYKuL51OefvpppKamomHDhvD390dOTg5eeeUVDBo0yOqi+aykpCQAKPB1UfuekRhmyCuMGDEC27Ztw+rVq60uis85fPgwRo8ejfj4eISEhFhdHJ/lcDjQtm1bvPrqqwCAVq1aYdu2bXj//fcZZnT2zTffYM6cOZg7dy6aNGmCxMREjBkzBtHR0axrH8VuJhdUqlQJ/v7+SE5Ozvf15ORkREVFWVQq3zVy5EgsXLgQy5YtQ7Vq1awujs/ZuHEjTpw4gdatWyMgIAABAQFYsWIFZsyYgYCAAOTk5FhdRJ9QpUoVNG7cON/XGjVqhEOHDllUIt/15JNP4umnn8bAgQPRrFkz3HvvvRg7diwmT55sddF8lvbaZ9XrIsOMC4KCgtCmTRssWbIk92sOhwNLlixBbGyshSXzLUopjBw5Ej/88AOWLl2KWrVqWV0kn9StWzf8/fffSExMzP1o27YtBg0ahMTERPj7+1tdRJ/QqVOny5YW2LNnD2rUqGFRiXzXhQsX4OeX/+XN398fDofDohL5vlq1aiEqKirf62JqairWrl1ryusiu5lcNG7cOAwePBht27ZFu3btMH36dKSnp+OBBx6wumg+Y8SIEZg7dy5+/PFHlC1bNrfftVy5cggNDbW4dL6jbNmyl41DKl26NCpWrMjxSToaO3YsOnbsiFdffRV33HEH1q1bhw8//BAffvih1UXzOf369cMrr7yC6tWro0mTJti8eTOmTZuGBx980OqiebW0tDTs27cv9/ODBw8iMTER4eHhqF69OsaMGYOXX34Z9erVQ61atfD8888jOjoat9xyi/GFM3y+lA+bOXOmql69ugoKClLt2rVTa9assbpIPgVAgR+fffaZ1UXzeZyabYyff/5ZNW3aVAUHB6uGDRuqDz/80Ooi+aTU1FQ1evRoVb16dRUSEqJq166tnn32WZWZmWl10bzasmXLCvyfPHjwYKWUTM9+/vnnVWRkpAoODlbdunVTu3fvNqVsNqW4JCIRERF5L46ZISIiIq/GMENERERejWGGiIiIvBrDDBEREXk1hhkiIiLyagwzRERE5NUYZoiIiMirMcwQERGRV2OYISIiIq/GMENERERejWGGiIiIvBrDDBEREXm1/wfmJ41R0VK45gAAAABJRU5ErkJggg==\n"},"metadata":{}}],"source":["x = tc.linspace(0, 10, 10000)\n","fig, ax = plot_func_and_deriv(x, f)"]},{"cell_type":"markdown","id":"c0a1f72a","metadata":{"id":"c0a1f72a"},"source":["### Step 4. Torch의 자동미분을 이용한 경사하강법"]},{"cell_type":"markdown","id":"72b0de77","metadata":{"id":"72b0de77"},"source":["#### 경사하강법 코드 수정하기 (1)"]},{"cell_type":"markdown","id":"6a2062d0","metadata":{"id":"6a2062d0"},"source":["자동미분을 이용하면 경사하강법을 쉽게 구현할 수 있다. 연습을 위해 간단한 일변수 함수에 대해 경사하강법을 수행해볼 것이다. 앞선 예제에서도 다룬적 있는 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n","\n","앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_parabola()를 작성해보았다.\n","\n","```python\n","def descent_down_parabola(w_start, learning_rate, num_steps):\n","    w_values = [w_start]\n","    for _ in range(num_steps):\n","        w_old = w_values[-1]\n","        w_new = w_old - learning_rate * (2 * w_old)\n","        w_values.append(w_new)\n","    return np.array(w_values)\n","```\n","\n","이번에는 도함수를 모르는 $\\mathscr{L}(w)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. $w$의 값을 PyTorch 텐서로 저장한 후, $\\mathscr{L}(w)$를 $w$의 식으로 정의해주어, .backward() 메서드를 사용하여 편미분계수를 구할 수 있다.\n","\n","아래의 경사하강법 공식에 따라 자동미분을 이용한 경사하강법을 프로그래밍으로 구현해보자.\n","\n","\\begin{equation}\n","w_{\\mathrm{new}} = w_{\\mathrm{old}} - \\delta \\frac{\\mathrm{d}\\mathscr{L}}{\\mathrm{d}w}\\big|_{w_{\\mathrm{old}}}\n","\\end{equation}"]},{"cell_type":"markdown","id":"2da681a1","metadata":{"id":"2da681a1"},"source":["다음과 같이 $w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."]},{"cell_type":"code","execution_count":68,"id":"941881f8","metadata":{"id":"941881f8","executionInfo":{"status":"ok","timestamp":1720165225893,"user_tz":-540,"elapsed":363,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["w = tc.tensor([10.0], requires_grad=True)\n","learning_rate = 0.3\n","num_steps = 20"]},{"cell_type":"markdown","id":"64bfcec4","metadata":{"id":"64bfcec4"},"source":["이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n","```\n","Tensor(4.)\n","Tensor(1.6)\n","Tensor(0.64)\n","Tensor(0.256)\n","Tensor(0.1024)\n","```"]},{"cell_type":"code","execution_count":67,"id":"7fda26a0","metadata":{"id":"7fda26a0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720165149178,"user_tz":-540,"elapsed":340,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"7457335a-4fe3-4297-c54a-6bf0fadef31e"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([4.], requires_grad=True)\n","tensor([1.6000], requires_grad=True)\n","tensor([0.6400], requires_grad=True)\n","tensor([0.2560], requires_grad=True)\n","tensor([0.1024], requires_grad=True)\n","tensor([0.0410], requires_grad=True)\n","tensor([0.0164], requires_grad=True)\n","tensor([0.0066], requires_grad=True)\n","tensor([0.0026], requires_grad=True)\n","tensor([0.0010], requires_grad=True)\n","tensor([0.0004], requires_grad=True)\n","tensor([0.0002], requires_grad=True)\n","tensor([6.7109e-05], requires_grad=True)\n","tensor([2.6844e-05], requires_grad=True)\n","tensor([1.0737e-05], requires_grad=True)\n","tensor([4.2950e-06], requires_grad=True)\n","tensor([1.7180e-06], requires_grad=True)\n","tensor([6.8719e-07], requires_grad=True)\n","tensor([2.7488e-07], requires_grad=True)\n","tensor([1.0995e-07], requires_grad=True)\n"]}],"source":["for _ in range(num_steps):\n","    ℒ = w ** 2\n","    ℒ.backward()\n","    # 여기에 코드 작성\n","\n","    #  블록 안에서 w를 업데이트. 이는 PyTorch가 이 블록 내의 연산을 추적하지 않도록 한다. -> 불필요한 메모리사용 없앰\n","    with tc.no_grad(): #메모리관리에 유리\n","        w -= learning_rate * w.grad\n","\n","    #w의 그래디언트를 초기화. 이를 통해 다음 단계에서 그래디언트가 누적되지 않도록 한다.\n","    w.grad = None\n","\n","    print(w)"]},{"cell_type":"markdown","id":"604b8e15","metadata":{"id":"604b8e15"},"source":["그런데 코드를 작성할 때, 한가지 생각해볼만한 부분이 있다. 위의 코드를 완성하여 원하는 출력값도 제대로 얻었다면, 아래의 두 코드와 자신의 답변을 비교해보자. 꼭 먼저 코드를 직접 작성해본 후에 답변을 확인하길 바란다.\n","\n","다음의 두 코드는 모두 원하는 출력값을 얻게 해주는 코드이다.\n","첫번째 코드는 다음과 같다.\n","```python\n","w = w - learning_rate * w.grad\n","```\n","두번째 코드는 다음과 같다.\n","```python\n","w.data -= learning_rate * w.grad\n","```"]},{"cell_type":"markdown","id":"205b2767","metadata":{"id":"205b2767"},"source":["두 코드는 동일한 출력값을 얻게 해줄 뿐 아니라, 사실상 같은 의미라고 느껴진다. 그리고 첫번째 코드가 우리가 알고 있는 공식에 더 가까원 형태이기 때문에 좀 더 직관적이다. 그러나, 두번째 코드는 두가지 이점이 있다.\n","\n","첫째로 컴퓨터 계산 속도를 최적화할 수 있다. 앞서 PyTorch의 텐서는 NumPy 배열의 수학적 연산들을 추적하는 추가 기능을 갖고 있는 객체라는 것을 배웠다. 그러나 이렇게 수학 연산을 추적하는 과정이 w 값을 갱신하는 과정에서는 굳이 필요하지 않다. 따라서 첫번째 코드와 같이 텐서를 사용하면, 불필요한 수학 연산의 추적으로 인해 간접적인 연산 처리 시간인 오버헤드(overhead)만 발생한다. 그러나 두번째 코드에서는 직접 텐서의 데이터를 업데이트함으로써, 불필요한 연산 그래프 추적을 피한다.\n","\n","둘째로 추가적인 메모리 공간을 필요로 하지 않는다. 연산자 '-='는 증강 업데이트(augmented update)를 실행하는 연산자이다. 이는 컴퓨터가 새로운 메모리 공간을 할당하여 배열의 값을 교체하는 대신, 사용하던 메모리 공간을 그대로 다시 덮어쓰는 것을 의미한다. 따라서 기존 메모리 공간을 그대로 사용하므로, 메모리 사용이 최적화된다.\n","\n","조만간 신경망에 대해 배운 후, 어렵고 복잡한 수학적 함수의 파라미터를 조정하게 되면, 수많은 대규모 데이터를 업데이트하게 될 것이다. 이런 상황에서 위의 두가지 이점은 학습의 성능에 큰 차이를 만들 것이다."]},{"cell_type":"markdown","id":"606ef82a","metadata":{"id":"606ef82a"},"source":["#### 경사하강법 코드 수정하기 (2)"]},{"cell_type":"markdown","id":"cf2419b9","metadata":{"id":"cf2419b9"},"source":["이번에는 앞선 예제에서 다룬적 있는 이변수 함수 $\\mathscr{L}(w_1, w_2) = 2w_1^2 + 3w_2^2$에 대한 경사하강법을 수행하며 자동미분을 잘 활용해보자.\n","\n","앞선 예제에서는 $\\mathscr{L}(w) = w^2$의 도함수가 $\\frac{d \\mathscr{L}}{d w} = 2w$임을 알고 있는 상태에서 경사하강법 함수 descent_down_2d_parabola()를 작성해보았다.\n","\n","```python\n","def descent_down_2d_parabola(w_start, learning_rate, num_steps):\n","    xy_values = [w_start]\n","    for _ in range(num_steps):\n","        xy_old = xy_values[-1]\n","        xy_new = xy_old - learning_rate * (np.array([4., 6.]) * xy_old)\n","        xy_values.append(xy_new)\n","    return np.array(xy_values)\n","```\n","\n","이번에는 도함수를 모르는 $\\mathscr{L}(w_1, w_2)$에 대해서도 적용할 수 있는, 자동미분을 이용한 경사하강법 함수를 작성해보자. 다차원 텐서로 정의된 함수의 자동미분을 잘 떠올리면 해결하는 데 도움이 될 것이다."]},{"cell_type":"markdown","id":"f0657ae3","metadata":{"id":"f0657ae3"},"source":["다음과 같이 $\\rm\\textbf w$의 시작점과 학습률 $\\delta$, 몇 단계 반복할 것인지가 주어졌다고 하자."]},{"cell_type":"code","execution_count":69,"id":"8ff9d793","metadata":{"id":"8ff9d793","executionInfo":{"status":"ok","timestamp":1720165245807,"user_tz":-540,"elapsed":2,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["w = tc.tensor([2., 4.], requires_grad=True)\n","learning_rate = 0.1\n","num_steps = 30"]},{"cell_type":"markdown","id":"c03fd2c5","metadata":{"id":"c03fd2c5"},"source":["이러한 상황에 대해 아래의 코드를 채워 경사하강법을 수행하는 코드를 작성해보자. 제대로 코드를 작성한다면, 다음과 같이 $w_1=0, w_2=0$으로 서서히 가까워지는 결과가 출력될 것이다.\n","```\n","Tensor([1.2, 1.6])\n","Tensor([0.72, 0.64])\n","Tensor([0.432, 0.256])\n","Tensor([0.2592, 0.1024])\n","Tensor([0.15552, 0.04096])\n","```"]},{"cell_type":"code","execution_count":70,"id":"6dc9819f","metadata":{"id":"6dc9819f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720165294102,"user_tz":-540,"elapsed":461,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"03b20066-6af7-493e-9c04-f36cef11489a"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([1.2000, 1.6000], requires_grad=True)\n","tensor([0.7200, 0.6400], requires_grad=True)\n","tensor([0.4320, 0.2560], requires_grad=True)\n","tensor([0.2592, 0.1024], requires_grad=True)\n","tensor([0.1555, 0.0410], requires_grad=True)\n","tensor([0.0933, 0.0164], requires_grad=True)\n","tensor([0.0560, 0.0066], requires_grad=True)\n","tensor([0.0336, 0.0026], requires_grad=True)\n","tensor([0.0202, 0.0010], requires_grad=True)\n","tensor([0.0121, 0.0004], requires_grad=True)\n","tensor([0.0073, 0.0002], requires_grad=True)\n","tensor([4.3536e-03, 6.7109e-05], requires_grad=True)\n","tensor([2.6121e-03, 2.6844e-05], requires_grad=True)\n","tensor([1.5673e-03, 1.0737e-05], requires_grad=True)\n","tensor([9.4037e-04, 4.2950e-06], requires_grad=True)\n","tensor([5.6422e-04, 1.7180e-06], requires_grad=True)\n","tensor([3.3853e-04, 6.8719e-07], requires_grad=True)\n","tensor([2.0312e-04, 2.7488e-07], requires_grad=True)\n","tensor([1.2187e-04, 1.0995e-07], requires_grad=True)\n","tensor([7.3123e-05, 4.3980e-08], requires_grad=True)\n","tensor([4.3874e-05, 1.7592e-08], requires_grad=True)\n","tensor([2.6324e-05, 7.0369e-09], requires_grad=True)\n","tensor([1.5795e-05, 2.8147e-09], requires_grad=True)\n","tensor([9.4768e-06, 1.1259e-09], requires_grad=True)\n","tensor([5.6861e-06, 4.5036e-10], requires_grad=True)\n","tensor([3.4116e-06, 1.8014e-10], requires_grad=True)\n","tensor([2.0470e-06, 7.2058e-11], requires_grad=True)\n","tensor([1.2282e-06, 2.8823e-11], requires_grad=True)\n","tensor([7.3691e-07, 1.1529e-11], requires_grad=True)\n","tensor([4.4215e-07, 4.6117e-12], requires_grad=True)\n"]}],"source":["const = tc.tensor([2.0, 3.0])\n","for _ in range(num_steps):\n","    ℒ = const * w ** 2\n","    ℒ.sum().backward()\n","    # 여기에 코드 작성\n","\n","    # w 업데이트 (메모리 최적화)\n","    with tc.no_grad():\n","        w -= learning_rate * w.grad\n","\n","    # w 값 출력\n","    print(w)\n","\n","    # 그래디언트 초기화\n","    w.grad.zero_()"]},{"cell_type":"markdown","id":"8f86fbb1","metadata":{"id":"8f86fbb1"},"source":["#### 일반적인 경사하강법 함수 작성하기"]},{"cell_type":"markdown","id":"633555d6","metadata":{"id":"633555d6"},"source":["일변수 함수, 다변수 함수에 대해 경사하강법을 수행해보았으니, 보편적인 상황에 대해 적용할 수 있는 일반적인 경사하강법 함수를 작성하는 것만 남았다."]},{"cell_type":"markdown","id":"78175514","metadata":{"id":"78175514"},"source":["<문제: 일반적인 경사하강법 함수 작성하기>\n","\n","이 문제의 목표는 어떤 함수가 어떤 텐서로 정의되어 있는지에 상관없이 사용할 수 있는 경사하강법 함수를 작성하는 것이다. 함수 외부에서 텐서와 텐서들로 정의된 함수를 모두 정의한 후, .backward() 메서드까지 실행한다. 함수 내부로는 텐서들만 전달해주어, 함수 내에서는 그 텐서들을 이용하여 경사하강법을 실행한다."]},{"cell_type":"markdown","id":"4d8ac2fb","metadata":{"id":"4d8ac2fb"},"source":["아래 함수의 주석을 잘 보고, 일반적인 경사하강법 함수를 작성해보자. 주석을 보면 이 함수는 단일 텐서를 인자로 입력받을 수도 있지만, 여러개의 텐서로 이루어진 iterable한 객체를 입력받을 수도 있다. 어떻게 코딩해야 할지 막막한 느낌이 든다면, 다음 힌트를 살펴보자.\n","\n","> HINT\n","> 1. 여러 개의 텐서로 이루어진 iterable한 자료형이 들어올 수 있으므로, for문을 이용하여 텐서를 하나씩 꺼내며 경사하강하는 코드를 작성해야한다.\n","> 2. 단일 텐서가 들어오면 for문을 이용할 수 없으므로, 단일 텐서를 단일 텐서가 들어있는 리스트로 바꾸어주는 과정이 있어야 한다."]},{"cell_type":"code","execution_count":71,"id":"db9666b8","metadata":{"id":"db9666b8","executionInfo":{"status":"ok","timestamp":1720165419136,"user_tz":-540,"elapsed":385,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["def gradient_step(tensors, learning_rate):\n","    \"\"\"\n","    경사하강법의 공식에 따라 gradient-step을 실행.\n","\n","    매개변수 (Parameters)\n","    ----------\n","    tensors : Union[Tensor, Iterable[Tensors]]\n","        단일 텐서, 혹은 텐서로 이루어진 iterable(리스트, 튜플 등) 모두 가능\n","        만약 특정 tensor에 대한 `tensor.grad`가 `None`인 경우, 업데이트를 건너 뜀\n","\n","    learning_rate : float\n","        매 gradient-step에서의 학습률. 양수\n","\n","    참고\n","    -----\n","    함수에서 진행되는 모든 gradient-steps는 tensor 내에서 바로 반영되므로, 반환 값 없음\n","    \"\"\"\n","    # isinstance 함수를 이용하여 입력된 tensors가 단일 텐서인지, iterable인지 판단한다\n","\n","    if isinstance(tensors, tc.Tensor):\n","        # Only one tensor was provided. Pack\n","        # it into a list so it can be accessed via\n","        # iteration\n","        tensors = [tensors]\n","\n","\n","    # for 문을 이용하여 tensors의 tensor를 하나씩 꺼내며 경사하강을 진행\n","    for t in tensors:\n","        if t.grad is not None:\n","            t.data -= learning_rate * t.grad\n","            t.grad.zero_()"]},{"cell_type":"markdown","id":"63edb99a","metadata":{"id":"63edb99a"},"source":["앞서 수행했던 함수 $\\mathscr{L}(w) = w^2$에 대한 경사하강법을 다시 한번 실행해봄으로써 보편적인 경사하강법 함수가 우리가 원하는대로 동작하는지 확인해보자."]},{"cell_type":"code","execution_count":75,"id":"fbf280d6","metadata":{"id":"fbf280d6","executionInfo":{"status":"ok","timestamp":1720165546526,"user_tz":-540,"elapsed":371,"user":{"displayName":"김성현","userId":"12634719816591505305"}}},"outputs":[],"source":["w = tc.tensor(10.0, requires_grad=True)\n","learning_rate = 0.3\n","num_steps = 10"]},{"cell_type":"code","execution_count":76,"id":"9abee228","metadata":{"id":"9abee228","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720165548607,"user_tz":-540,"elapsed":357,"user":{"displayName":"김성현","userId":"12634719816591505305"}},"outputId":"76bc791c-f5f0-41d5-8271-9bc83d97712b"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(4., requires_grad=True)\n","tensor(1.6000, requires_grad=True)\n","tensor(0.6400, requires_grad=True)\n","tensor(0.2560, requires_grad=True)\n","tensor(0.1024, requires_grad=True)\n","tensor(0.0410, requires_grad=True)\n","tensor(0.0164, requires_grad=True)\n","tensor(0.0066, requires_grad=True)\n","tensor(0.0026, requires_grad=True)\n","tensor(0.0010, requires_grad=True)\n"]}],"source":["for _ in range(num_steps):\n","    ℒ = w ** 2\n","    ℒ.backward()\n","    gradient_step(w, learning_rate = learning_rate)\n","    print(w)"]},{"cell_type":"markdown","id":"99313c60","metadata":{"id":"99313c60"},"source":["### 배운 내용 되돌아보기"]},{"cell_type":"markdown","id":"cecca3d9","metadata":{"id":"cecca3d9"},"source":["이번 실습에서는 자동미분을 도와주는 PyTorch 라이브러리의 사용법을 배우고 익혔다. PyTorch는 앞으로의 거의 모든 실습에서 사용되는 중요한 라이브러리이다.\n","\n","- Tensor를 생성하는 여러 가지 함수들을 사용해보았다. 원소를 직접 적어줄 수도 있고, 리스트, 튜플, NumPy의 ndarray 등으로부터 Tensor를 생성할 수도 있었다.\n","\n","- 기존에 생성된 Tensor의 행과 열을 자유자재로 바꾸거나 일부 행이나 열만 슬라이싱 해보았다.\n","\n","- PyTorch에서 제공하는 다양한 수학 연산 함수들을 사용해보았다. 그 과정에서 NumPy의 함수들과의 유사성을 확인하였다.\n","\n","- 선형대수 연산을 돕는 함수인 matmul()과 einsum()을 사용해보았다.\n","\n","- PyTorch에 딥러닝을 위한 특수 함수들이 다양하게 존재함을 알게 되었으나, 사용해보지는 않았다.\n","\n","- PyTorch 텐서 객체의 .backward() 메서드를 사용하여 자동미분을 실행하고, 텐서의 .grad 속성을 이용하여 편미분 계수를 구해보았다.\n","\n","- 경사하강을 반복하며 최적의 모델을 찾아갈 때, 경사하강이 1회 종료될 때마다 기존의 편미분 계수를 폐기해주어야 함을 알게 되었다. 이를 위해 .grad 속성을 폐기하는 방법을 직접 사용해보았다.\n","\n","- PyTorch 텐서와 NumPy의 배열 사이의 관계를 알게 되었다.\n","\n","- 불필요한 편미분 계수를 계산하는 것을 방지하기 위해, 텐서를 상수 취급하는 방법을 도입해야 함을 알게 되었다. 그리고 텐서를 상수 취급하기 위한 방법을 사용해보았다.\n","\n","- 다차원 텐서에 대해 정의된 함수 (다변수 함수)에서 자동미분을 실행하면 다차원 텐서의 각 원소가 스칼라 값 변수로 해석되어 자동미분이 이루어짐을 알게 되었다. 또한 다차원 텐서의 .grad 속성에 함수의 그래디언트 값이 저장됨을 확인하였다.\n","\n","- 다변수 벡터 함수에 대해 자동미분을 실행하면 모든 성분함수를 합한 것에 대해 자동미분이 이루어짐을 알게 되었다. 또한 이런 규칙이 어떤 유용함을 가지는지 확인하였다.\n","\n","- PyTorch의 자동미분을 이용하여 경사하강법 함수를 새롭게 구현해보았다."]},{"cell_type":"code","execution_count":null,"id":"649f5f3b","metadata":{"id":"649f5f3b"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}